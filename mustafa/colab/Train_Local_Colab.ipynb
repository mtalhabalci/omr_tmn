{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Colab Runtime and Dependencies (Cell 1)\n",
    "!pip install --quiet torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --quiet -r /content/drive/MyDrive/requirements.txt || echo \"requirements.txt bulunamadƒ±, atlanƒ±yor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and Project Structure (Cell 2)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/omr_colab'\n",
    "for p in ['colab','data','outputs','outputs/logs','outputs/checkpoints','outputs/artifacts']:\n",
    "    os.makedirs(os.path.join(PROJECT_ROOT, p), exist_ok=True)\n",
    "print({'PROJECT_ROOT': PROJECT_ROOT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset Paths and Config (Cell 3)\n",
    "import json, os\n",
    "CONFIG = {\n",
    "    'train_data': f\"{PROJECT_ROOT}/data/train\",\n",
    "    'val_data': f\"{PROJECT_ROOT}/data/val\",\n",
    "    'output_dir': f\"{PROJECT_ROOT}/outputs\",\n",
    "    'batch_size': 1,\n",
    "    'epochs': 10,\n",
    "    'min_size': [256],\n",
    "    'max_size': 512,\n",
    "    'num_workers': 2\n",
    "}\n",
    "CFG_PATH = f\"{PROJECT_ROOT}/colab/config.json\"\n",
    "os.makedirs(os.path.dirname(CFG_PATH), exist_ok=True)\n",
    "with open(CFG_PATH, 'w', encoding='utf-8') as f: json.dump(CONFIG, f, ensure_ascii=False, indent=2)\n",
    "print({'CONFIG_PATH': CFG_PATH, 'CONFIG': CONFIG})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25702699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo'daki train_local.py i√ßeriƒüini Drive'a yaz (Cell 4)\n",
    "import os\n",
    "code = r\"\"\"\n",
    "# LOCAL TRAINING VERSION - CPU Optimized\n",
    "# Windows local ortamƒ± i√ßin optimize edilmi≈ü MaskRCNN eƒüitim kodu\n",
    "\n",
    "import sys, os\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json, glob, time, gc\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print('='*60)\n",
    "print('üñ•Ô∏è  LOCAL TRAINING MODE - CPU')\n",
    "print('='*60)\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Torchvision: {torchvision.__version__}')\n",
    "print(f'Device: CPU (GPU disabled)')\n",
    "print('='*60)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIG - Local Windows Paths\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # üîß PATHS (Colab/Drive uyumlu)\n",
    "    DATASET_NAME: str = 'ds2_dense_tmn3'\n",
    "    BASE_DIR: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2'\n",
    "    \n",
    "    # Dataset paths (otomatik olu≈üturulacak)\n",
    "    OUT_ROOT: str = None\n",
    "    IMG_ROOT: str = None\n",
    "    TRAIN_ROOT: str = None\n",
    "    MASKRCNN_ROOT: str = None\n",
    "    \n",
    "    # üíª CPU Optimized Settings\n",
    "    BATCH_SIZE: int = 1  # CPU i√ßin 1 yeterli\n",
    "    EPOCHS: int = 2  # Test i√ßin kƒ±sa\n",
    "    NUM_WORKERS: int = 0  # Windows + CPU i√ßin 0 √∂nerilir\n",
    "    \n",
    "    # Model hyperparameters\n",
    "    LR: float = 0.001  # CPU i√ßin daha d√º≈ü√ºk\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 0.0005\n",
    "    \n",
    "    # Memory settings\n",
    "    MAX_INSTANCES: Optional[int] = 50  # CPU RAM i√ßin limit\n",
    "    DATA_LOADER_PIN_MEMORY: bool = False\n",
    "    \n",
    "    # Image size (CPU i√ßin k√º√ß√ºk)\n",
    "    MIN_SIZE: int = 256\n",
    "    MAX_SIZE: int = 512\n",
    "    \n",
    "    # Evaluation\n",
    "    EVAL_SPLIT: str = 'test'\n",
    "    EVAL_SCORE_THR: float = 0.05\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Otomatik path olu≈üturma\"\"\"\n",
    "        dataset_path = Path(self.BASE_DIR) / self.DATASET_NAME\n",
    "        \n",
    "        if not dataset_path.exists():\n",
    "            raise FileNotFoundError(f\"Dataset bulunamadƒ±: {dataset_path}\")\n",
    "        \n",
    "        self.OUT_ROOT = str(dataset_path)\n",
    "        self.IMG_ROOT = str(dataset_path / 'images')\n",
    "        self.TRAIN_ROOT = str(Path(self.BASE_DIR) / 'train' / self.DATASET_NAME)\n",
    "        self.MASKRCNN_ROOT = str(Path(self.TRAIN_ROOT) / 'maskrcnn')\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset found: {dataset_path}\")\n",
    "        print(f\"üìÅ Images: {len(list((dataset_path / 'images').glob('*')))} files\")\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# ============================================================================\n",
    "# RUN DIRECTORY\n",
    "# ============================================================================\n",
    "\n",
    "os.makedirs(cfg.MASKRCNN_ROOT, exist_ok=True)\n",
    "RUN_DIR = os.path.join(cfg.MASKRCNN_ROOT, time.strftime('%Y%m%d_%H%M%S') + '_local_cpu')\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print(f'\\nüìÇ RUN_DIR: {RUN_DIR}')\n",
    "\n",
    "# ============================================================================\n",
    "# LOGGING\n",
    "# ============================================================================\n",
    "\n",
    "LOG_DIR = os.path.join(RUN_DIR, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(LOG_DIR, 'train.log')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logging.info('='*60)\n",
    "logging.info('LOCAL TRAINING STARTED (CPU Mode)')\n",
    "logging.info('='*60)\n",
    "\n",
    "# ============================================================================\n",
    "# CATEGORY MAPPING\n",
    "# ============================================================================\n",
    "\n",
    "train_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "\n",
    "logging.info(f\"Train JSON files: {len(train_jsons)}\")\n",
    "logging.info(f\"Test JSON files: {len(test_jsons)}\")\n",
    "\n",
    "def build_category_maps(json_paths):\n",
    "    \"\"\"T√ºm kategorileri topla ve mapping olu≈ütur\"\"\"\n",
    "    cats = set()\n",
    "    for jp in json_paths:\n",
    "        try:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"JSON okuma hatasƒ± {jp}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        anns = data.get('annotations') or {}\n",
    "        ann_iter = anns.values() if isinstance(anns, dict) else anns\n",
    "        \n",
    "        for a in ann_iter:\n",
    "            cats_val = a.get('cat_id') or a.get('category_id')\n",
    "            if isinstance(cats_val, list):\n",
    "                for c in cats_val:\n",
    "                    try:\n",
    "                        cats.add(int(c))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            elif cats_val is not None:\n",
    "                try:\n",
    "                    cats.add(int(cats_val))\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "    cats = sorted(cats)\n",
    "    cat_map = {orig: i+1 for i, orig in enumerate(cats)}  # 0: background\n",
    "    inv_cat_map = {v: k for k, v in cat_map.items()}\n",
    "    return cat_map, inv_cat_map\n",
    "\n",
    "ALL_JSONS = train_jsons + test_jsons\n",
    "CAT_MAP, INV_CAT_MAP = build_category_maps(ALL_JSONS)\n",
    "NUM_CLASSES = 1 + len(CAT_MAP)\n",
    "\n",
    "logging.info(f\"‚úÖ Categories: {len(CAT_MAP)}, Total classes: {NUM_CLASSES}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LAZY LOADING DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class DS2TMNDataset(Dataset):\n",
    "    \"\"\"Lazy loading dataset - RAM dostu\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, json_paths, transform=None, max_instances=None, category_map=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.max_instances = max_instances\n",
    "        self.category_map = category_map\n",
    "        self.json_paths = json_paths\n",
    "        self.items = []\n",
    "        \n",
    "        # Sadece g√∂r√ºnt√º listesini topla\n",
    "        seen_fn = set()\n",
    "        for json_idx, jp in enumerate(json_paths):\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            imgs = data.get('images') or []\n",
    "            if isinstance(imgs, dict):\n",
    "                imgs = list(imgs.values())\n",
    "            \n",
    "            for im in imgs:\n",
    "                fn = im.get('filename') or im.get('file_name')\n",
    "                if not fn or fn in seen_fn:\n",
    "                    continue\n",
    "                seen_fn.add(fn)\n",
    "                \n",
    "                try:\n",
    "                    iid = int(im.get('id')) if im.get('id') is not None else -1\n",
    "                except Exception:\n",
    "                    iid = -1\n",
    "                \n",
    "                self.items.append({\n",
    "                    'filename': fn,\n",
    "                    'image_id': iid,\n",
    "                    'json_idx': json_idx\n",
    "                })\n",
    "        \n",
    "        self.items.sort(key=lambda x: x['filename'])\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "        \n",
    "        logging.info(f\"‚úÖ Dataset ready: {len(self.items)} images (filtering skipped for speed)\")\n",
    "    \n",
    "    def _load_annotations_for_image(self, filename, image_id):\n",
    "        \"\"\"Lazy loading: Sadece bu g√∂r√ºnt√ºn√ºn annotation'larƒ±nƒ± y√ºkle\"\"\"\n",
    "        annotations = []\n",
    "        \n",
    "        for jp in self.json_paths:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            anns = data.get('annotations') or {}\n",
    "            ann_iter = anns.values() if isinstance(anns, dict) else anns\n",
    "            \n",
    "            for a in ann_iter:\n",
    "                img_id = a.get('img_id') or a.get('image_id')\n",
    "                if img_id != image_id:\n",
    "                    continue\n",
    "                \n",
    "                b = a.get('a_bbox') or a.get('bbox')\n",
    "                cats = a.get('cat_id') or a.get('category_id') or []\n",
    "                if not b or len(b) < 4:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(cats, list) and len(cats) > 0:\n",
    "                    orig_lab = int(cats[0])\n",
    "                elif isinstance(cats, (int, str)):\n",
    "                    orig_lab = int(cats)\n",
    "                else:\n",
    "                    orig_lab = 0\n",
    "                \n",
    "                if self.category_map is not None:\n",
    "                    mapped = self.category_map.get(orig_lab)\n",
    "                    if mapped is None:\n",
    "                        continue\n",
    "                    lab_to_use = int(mapped)\n",
    "                else:\n",
    "                    lab_to_use = int(orig_lab)\n",
    "                \n",
    "                annotations.append([\n",
    "                    float(b[0]), float(b[1]), float(b[2]), float(b[3]), lab_to_use\n",
    "                ])\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im = self.items[idx]\n",
    "        fn = im['filename']\n",
    "        img_id = int(im['image_id'])\n",
    "        path = os.path.join(self.images_dir, fn)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Image load error {fn}: {e}\")\n",
    "            W = H = 1\n",
    "            img = Image.new('RGB', (W, H), (0, 0, 0))\n",
    "            lst = []\n",
    "        else:\n",
    "            W, H = img.size\n",
    "            lst = self._load_annotations_for_image(fn, img_id)\n",
    "        \n",
    "        boxes_labels = []\n",
    "        for rec in lst:\n",
    "            x1, y1, x2, y2, lab = rec\n",
    "            x1 = max(0, min(x1, W - 1))\n",
    "            y1 = max(0, min(y1, H - 1))\n",
    "            x2 = max(0, min(x2, W))\n",
    "            y2 = max(0, min(y2, H))\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                boxes_labels.append((x1, y1, x2, y2, lab))\n",
    "        \n",
    "        if len(boxes_labels) == 0:\n",
    "            for attempt in range(10):\n",
    "                next_idx = (idx + attempt + 1) % len(self.items)\n",
    "                try:\n",
    "                    return self.__getitem__(next_idx)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            boxes_labels = [(0, 0, min(10, W), min(10, H), 1)]\n",
    "        \n",
    "        if self.max_instances and len(boxes_labels) > self.max_instances:\n",
    "            boxes_labels = boxes_labels[:self.max_instances]\n",
    "        \n",
    "        boxes = [[x1, y1, x2, y2] for x1, y1, x2, y2, _ in boxes_labels]\n",
    "        labels = [lab for *_, lab in boxes_labels]\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            masks = torch.zeros((len(boxes), H, W), dtype=torch.bool)\n",
    "            for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "                masks[i, int(y1):int(y2), int(x1):int(x2)] = True\n",
    "        else:\n",
    "            masks = torch.zeros((0, H, W), dtype=torch.bool)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'masks': masks,\n",
    "            'image_id': torch.tensor([img_id], dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        img = self.transform(img) if self.transform else self.to_tensor(img)\n",
    "        return img, target\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "train_ds = DS2TMNDataset(\n",
    "    images_dir=cfg.IMG_ROOT,\n",
    "    json_paths=train_jsons,\n",
    "    max_instances=cfg.MAX_INSTANCES,\n",
    "    category_map=CAT_MAP\n",
    ")\n",
    "\n",
    "test_ds = DS2TMNDataset(\n",
    "    images_dir=cfg.IMG_ROOT,\n",
    "    json_paths=test_jsons,\n",
    "    max_instances=cfg.MAX_INSTANCES,\n",
    "    category_map=CAT_MAP\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.NUM_WORKERS,\n",
    "    pin_memory=cfg.DATA_LOADER_PIN_MEMORY,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.NUM_WORKERS,\n",
    "    pin_memory=cfg.DATA_LOADER_PIN_MEMORY,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "logging.info(f\"‚úÖ Train loader: {len(train_ds)} images, {len(train_loader)} batches\")\n",
    "logging.info(f\"‚úÖ Test loader: {len(test_ds)} images, {len(test_loader)} batches\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL - MobileNetV3 (Lightweight for CPU)\n",
    "# ============================================================================\n",
    "\n",
    "logging.info(\"üèóÔ∏è  Building MobileNetV3 Mask R-CNN (CPU optimized)...\")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "try:\n",
    "    from torchvision.models.detection import maskrcnn_mobilenet_v3_large_fpn\n",
    "    model = maskrcnn_mobilenet_v3_large_fpn(num_classes=NUM_CLASSES, weights=None)\n",
    "    used_impl = 'factory'\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Factory method failed: {e}\")\n",
    "    from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
    "    from torchvision.models.detection import MaskRCNN\n",
    "    backbone = mobilenet_backbone('mobilenet_v3_large', pretrained=False, fpn=True, trainable_layers=3)\n",
    "    model = MaskRCNN(backbone, num_classes=NUM_CLASSES)\n",
    "    used_impl = 'backbone_utils'\n",
    "\n",
    "if hasattr(model, 'transform'):\n",
    "    if hasattr(model.transform, 'min_size'):\n",
    "        model.transform.min_size = [cfg.MIN_SIZE]\n",
    "    if hasattr(model.transform, 'max_size'):\n",
    "        model.transform.max_size = cfg.MAX_SIZE\n",
    "\n",
    "if hasattr(model, 'roi_heads'):\n",
    "    if hasattr(model.roi_heads, 'detections_per_img'):\n",
    "        model.roi_heads.detections_per_img = 20\n",
    "    if hasattr(model.roi_heads, 'box_batch_size_per_image'):\n",
    "        model.roi_heads.box_batch_size_per_image = 64\n",
    "\n",
    "model.to(device)\n",
    "logging.info(f\"‚úÖ Model ready: MaskRCNN-MobileNetV3 (via {used_impl}) on CPU\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "optimizer = SGD(\n",
    "    model.parameters(),\n",
    "    lr=cfg.LR,\n",
    "    momentum=cfg.MOMENTUM,\n",
    "    weight_decay=cfg.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "CKPT_DIR = os.path.join(RUN_DIR, 'checkpoints')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "logging.info(\"=\"*60)\n",
    "logging.info(f\"üöÄ TRAINING START: {cfg.EPOCHS} epochs\")\n",
    "logging.info(\"=\"*60)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    total_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += losses.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        del images, targets, loss_dict, losses\n",
    "        gc.collect()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            avg_loss = total_loss / batch_count\n",
    "            logging.info(f\"Epoch {epoch+1}/{cfg.EPOCHS} | Batch {batch_idx+1}/{len(train_loader)} | Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    epoch_duration = time.time() - epoch_start\n",
    "    avg_loss = total_loss / max(1, len(train_loader))\n",
    "    \n",
    "    logging.info(\"=\"*60)\n",
    "    logging.info(f\"‚úÖ Epoch {epoch+1}/{cfg.EPOCHS} Complete\")\n",
    "    logging.info(f\"   Loss: {avg_loss:.4f}\")\n",
    "    logging.info(f\"   Duration: {epoch_duration:.1f}s ({epoch_duration/60:.1f} min)\")\n",
    "    logging.info(\"=\"*60)\n",
    "    \n",
    "    ckpt_path = os.path.join(CKPT_DIR, f'maskrcnn_epoch{epoch+1}.pt')\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, ckpt_path)\n",
    "    logging.info(f\"üíæ Checkpoint saved: {ckpt_path}\")\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "logging.info(\"=\"*60)\n",
    "logging.info(\"‚úÖ TRAINING COMPLETE!\")\n",
    "logging.info(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"RUN_DIR: {RUN_DIR}\")\n",
    "print(f\"Checkpoints: {len(glob.glob(os.path.join(CKPT_DIR, '*.pt')))} files\")\n",
    "print(f\"Logs: {LOG_DIR}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ Kod ba≈üarƒ±yla tamamlandƒ±!\")\n",
    "print(\"Checkpoint'leri test etmek i√ßin model.load_state_dict() kullanabilirsiniz.\\n\")\n",
    "\"\"\"\n",
    "\n",
    "TRAIN_SCRIPT_PATH = f\"{PROJECT_ROOT}/colab/train_local.py\"\n",
    "os.makedirs(os.path.dirname(TRAIN_SCRIPT_PATH), exist_ok=True)\n",
    "with open(TRAIN_SCRIPT_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(code)\n",
    "print({'TRAIN_SCRIPT_PATH': TRAIN_SCRIPT_PATH, 'bytes': len(code)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ebfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Training and Stream Output (Cell 5)\n",
    "!python \"$PROJECT_ROOT/colab/train_local.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Metrics and Save Checkpoints to Drive (Cell 6)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"$PROJECT_ROOT/outputs/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume Training from Last Checkpoint (Cell 7)\n",
    "import glob, os\n",
    "ckpts = glob.glob(f\"{PROJECT_ROOT}/outputs/checkpoints/*.pt\")\n",
    "ckpts.sort(key=os.path.getmtime)\n",
    "LAST_CKPT = ckpts[-1] if ckpts else None\n",
    "print({'LAST_CKPT': LAST_CKPT})\n",
    "if LAST_CKPT:\n",
    "    !python \"$PROJECT_ROOT/colab/train_local.py\" --config \"$PROJECT_ROOT/colab/config.json\" --output-dir \"$PROJECT_ROOT/outputs\" --resume \"$LAST_CKPT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Validation/Test Set (Cell 8)\n",
    "CKPT_PATH = LAST_CKPT if 'LAST_CKPT' in globals() and LAST_CKPT else f\"{PROJECT_ROOT}/outputs/checkpoints/last.pt\"\n",
    "!python \"$PROJECT_ROOT/colab/train_local.py\" --config \"$PROJECT_ROOT/colab/config.json\" --output-dir \"$PROJECT_ROOT/outputs\" --evaluate --checkpoint \"$CKPT_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model Artifacts for VS Code (Cell 9)\n",
    "import torch, os\n",
    "ART_DIR = f\"{PROJECT_ROOT}/outputs/artifacts\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "SRC = f\"{PROJECT_ROOT}/outputs/checkpoints/last.pt\"\n",
    "DST = os.path.join(ART_DIR, 'model_last.pt')\n",
    "if os.path.exists(SRC):\n",
    "    import shutil; shutil.copy2(SRC, DST)\n",
    "    print({'exported': DST})\n",
    "else:\n",
    "    print('No checkpoint to export.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e97c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 2\n",
    "\n",
    "# Colab ve Drive mount\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping Drive mount.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c765f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 3\n",
    "\n",
    "# Repo klonla ve çalışma dizinini ayarla\n",
    "import os, sys, subprocess\n",
    "REPO_URL = 'https://github.com/mtalhabalci/omr_tmn.git'\n",
    "WORKDIR = '/content/omr_tmn'\n",
    "SCRIPT_PATH = None\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.isdir(WORKDIR):\n",
    "        print('Cloning repo...')\n",
    "        subprocess.check_call(['git','clone',REPO_URL, WORKDIR])\n",
    "    else:\n",
    "        print('Repo exists; pulling latest...')\n",
    "        subprocess.call(['bash','-lc', f'cd {WORKDIR} && git pull --rebase'])\n",
    "    os.chdir(WORKDIR)\n",
    "    print('Changed dir to', os.getcwd())\n",
    "    candidate = os.path.join(WORKDIR, 'src', 'place_tmn_batch.py')\n",
    "    if os.path.isfile(candidate):\n",
    "        SCRIPT_PATH = candidate\n",
    "    else:\n",
    "        alt = os.path.join(WORKDIR, 'place_tmn_batch.py')\n",
    "        SCRIPT_PATH = alt if os.path.isfile(alt) else candidate\n",
    "    print({'SCRIPT_PATH': SCRIPT_PATH, 'exists': os.path.isfile(SCRIPT_PATH)})\n",
    "else:\n",
    "    print('Not in Colab; skipping clone and cd.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 4\n",
    "\n",
    "# DS2 Complete kaynak ve TMN çıktı yollarını ayarla\n",
    "import os\n",
    "SRC_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete'\n",
    "OUT_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete_tmn'\n",
    "SRC_IMAGES = f\"{SRC_ROOT}/images\"\n",
    "print({'SRC_ROOT': SRC_ROOT, 'OUT_ROOT': OUT_ROOT, 'SRC_IMAGES': SRC_IMAGES})\n",
    "\n",
    "# Çıktı klasörlerini hazırla\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'segmentation'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'instance'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'logs'), exist_ok=True)\n",
    "INDEX_DIR = os.path.join(OUT_ROOT, 'index')\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "print({'INDEX_DIR': INDEX_DIR})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 5\n",
    "\n",
    "# Image→JSON mapping index üret (CSV)\n",
    "import os, glob, json\n",
    "from collections import OrderedDict\n",
    "\n",
    "train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')))\n",
    "test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "if not train_shards and not test_shards:\n",
    "    train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*train*.json')))\n",
    "    test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*test*.json')))\n",
    "shards = train_shards + test_shards\n",
    "print({'shard_count': len(shards)})\n",
    "\n",
    "# Öncelik: train sonra test\n",
    "ordered_shards = train_shards + test_shards\n",
    "image_to_json = OrderedDict()\n",
    "duplicates = []\n",
    "missing = []\n",
    "\n",
    "def image_name_from_entry(im):\n",
    "    if isinstance(im, dict):\n",
    "        return im.get('filename') or im.get('file_name')\n",
    "    return None\n",
    "\n",
    "for jp in ordered_shards:\n",
    "    try:\n",
    "        with open(jp, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        imgs = data.get('images') or []\n",
    "        if isinstance(imgs, dict):\n",
    "            imgs = list(imgs.values())\n",
    "        for im in imgs:\n",
    "            nm = image_name_from_entry(im)\n",
    "            if not nm:\n",
    "                continue\n",
    "            if nm in image_to_json:\n",
    "                duplicates.append((nm, os.path.basename(jp)))\n",
    "                continue\n",
    "            p = os.path.join(SRC_IMAGES, nm)\n",
    "            if not os.path.isfile(p):\n",
    "                missing.append(nm)\n",
    "                # yine de index'e ekleyebiliriz; ama raporlayalım\n",
    "            image_to_json[nm] = os.path.basename(jp)\n",
    "    except Exception as e:\n",
    "        print('Read failed for', jp, e)\n",
    "\n",
    "# CSV yaz\n",
    "CSV_PATH = os.path.join(INDEX_DIR, 'image_to_json.csv')\n",
    "with open(CSV_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write('image_name,json_shard\\n')\n",
    "    for nm, shard in image_to_json.items():\n",
    "        f.write(f\"{nm},{shard}\\n\")\n",
    "print({'index_csv': CSV_PATH, 'mapped_images': len(image_to_json)})\n",
    "\n",
    "# Duplicates ve missing raporları\n",
    "DUP_PATH = os.path.join(INDEX_DIR, 'duplicates.csv')\n",
    "with open(DUP_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write('image_name,also_in_shard\\n')\n",
    "    for nm, sh in duplicates[:1000]:\n",
    "        f.write(f\"{nm},{sh}\\n\")\n",
    "MIS_PATH = os.path.join(INDEX_DIR, 'missing_images.csv')\n",
    "with open(MIS_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write('image_name\\n')\n",
    "    for nm in sorted(set(missing))[:5000]:\n",
    "        f.write(f\"{nm}\\n\")\n",
    "print({'duplicates_written': len(duplicates), 'missing_written': len(set(missing))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 6\n",
    "\n",
    "# Shard bazlı küçük batch koşusu (test)\n",
    "import sys, subprocess, os, glob, time\n",
    "\n",
    "# Script konumunu doğrula\n",
    "sp_candidates = []\n",
    "try:\n",
    "    if 'SCRIPT_PATH' in globals() and isinstance(SCRIPT_PATH, str):\n",
    "        sp_candidates.append(SCRIPT_PATH)\n",
    "except Exception:\n",
    "    pass\n",
    "sp_candidates += [\n",
    "    os.path.join('/content/omr_tmn', 'src', 'place_tmn_batch.py'),\n",
    "    os.path.join('/content/omr_tmn', 'place_tmn_batch.py'),\n",
    "    'src/place_tmn_batch.py'\n",
    "]\n",
    "SCRIPT_TO_RUN = next((p for p in sp_candidates if os.path.isfile(p)), None)\n",
    "print({'SCRIPT_TO_RUN': SCRIPT_TO_RUN, 'exists': bool(SCRIPT_TO_RUN and os.path.isfile(SCRIPT_TO_RUN))})\n",
    "if not SCRIPT_TO_RUN:\n",
    "    print('ERROR: place_tmn_batch.py not found.')\n",
    "\n",
    "# Shardları topla\n",
    "train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')))\n",
    "test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "if not train_shards and not test_shards:\n",
    "    train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*train*.json')))\n",
    "    test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*test*.json')))\n",
    "shards = train_shards + test_shards\n",
    "print({'shard_count': len(shards), 'sample_shards': [os.path.basename(x) for x in shards[:5]]})\n",
    "\n",
    "LOG_DIR = os.path.join(OUT_ROOT, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Sadece ilk shard ile küçük limit (50) test\n",
    "shards_to_run = shards[:1]\n",
    "for jp in shards_to_run:\n",
    "    base = os.path.basename(jp)\n",
    "    done_marker = os.path.join(LOG_DIR, base + '.done')\n",
    "    t0 = time.time()\n",
    "    if SCRIPT_TO_RUN:\n",
    "        cmd = [\n",
    "            sys.executable, '-u', SCRIPT_TO_RUN,\n",
    "            '--images-dir', SRC_IMAGES,\n",
    "            '--out-root', OUT_ROOT,\n",
    "            '--json-path', jp,\n",
    "            '--checkpoint', '200',\n",
    "            '--json-out-mode', 'per-shard',\n",
    "            '--symbols-dir', '/content/omr_tmn/tmn_symbols_png',\n",
    "            '--force',\n",
    "            '--slot-w', '12',\n",
    "            '--slot-h', '36',\n",
    "            '--limit', '50'\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [sys.executable, '-u', '-c', \"import sys; print('script missing'); sys.exit(2)\"]\n",
    "\n",
    "    print('Running shard:', base)\n",
    "    print('Command:', ' '.join(cmd))\n",
    "\n",
    "    TIMEOUT_PER_SHARD = int(os.environ.get('TMN_TIMEOUT_SEC', '3600'))\n",
    "    HEARTBEAT_SEC = int(os.environ.get('TMN_HEARTBEAT_SEC', '30'))\n",
    "    last_beat = time.time()\n",
    "    combined_tail = []\n",
    "\n",
    "    ret = None\n",
    "    try:\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "        while True:\n",
    "            line = p.stdout.readline()\n",
    "            if not line:\n",
    "                if p.poll() is not None:\n",
    "                    break\n",
    "                time.sleep(0.2)\n",
    "                continue\n",
    "            line = line.rstrip('\n",
    "')\n",
    "            if line:\n",
    "                print(line)\n",
    "                combined_tail.append(line)\n",
    "                if len(combined_tail) > 200:\n",
    "                    combined_tail = combined_tail[-200:]\n",
    "            now = time.time()\n",
    "            if now - last_beat >= HEARTBEAT_SEC:\n",
    "                elapsed = int(now - t0)\n",
    "                print(f\"[heartbeat] {base} running {elapsed}s...\")\n",
    "                last_beat = now\n",
    "            if now - t0 > TIMEOUT_PER_SHARD:\n",
    "                print(f\"Timeout after {TIMEOUT_PER_SHARD}s; terminating shard {base}\")\n",
    "                try:\n",
    "                    p.terminate(); p.wait(timeout=10)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                try:\n",
    "                    p.kill()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                ret = 124\n",
    "                break\n",
    "        if ret is None:\n",
    "            ret = p.wait()\n",
    "    except Exception as e:\n",
    "        print('Runner failed:', e)\n",
    "        ret = 2\n",
    "\n",
    "    # OUT_ROOT/jsonlar altındaki JSON'ları köke taşı\n",
    "import shutil\n",
    "moved = []\n",
    "jsonlar_dir = os.path.join(OUT_ROOT, 'jsonlar')\n",
    "if os.path.isdir(jsonlar_dir):\n",
    "    for f in glob.glob(os.path.join(jsonlar_dir, '*.json')):\n",
    "        dest = os.path.join(OUT_ROOT, os.path.basename(f))\n",
    "        try:\n",
    "            os.replace(f, dest)\n",
    "            moved.append(os.path.basename(f))\n",
    "        except Exception as e:\n",
    "            print('Move failed', f, '->', dest, e)\n",
    "    try:\n",
    "        if not os.listdir(jsonlar_dir):\n",
    "            os.rmdir(jsonlar_dir)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Yeni üretilen dosya sayıları\n",
    "def count_new(dir_path, suffix):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for nm in os.listdir(dir_path):\n",
    "            if suffix and not nm.lower().endswith(suffix):\n",
    "                continue\n",
    "            pth = os.path.join(dir_path, nm)\n",
    "            try:\n",
    "                if os.stat(pth).st_mtime >= t0:\n",
    "                    cnt += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    return cnt\n",
    "new_imgs = count_new(os.path.join(OUT_ROOT, 'images'), '.png')\n",
    "new_segs = count_new(os.path.join(OUT_ROOT, 'segmentation'), '_seg.png')\n",
    "new_insts = count_new(os.path.join(OUT_ROOT, 'instance'), '_inst.png')\n",
    "\n",
    "dur = round(time.time() - t0, 1)\n",
    "try:\n",
    "    with open(os.path.join(LOG_DIR, 'run.csv'), 'a', encoding='utf-8') as lf:\n",
    "        lf.write(f\"{base},{ret},{dur},{len(moved)}\\n\")\n",
    "except Exception as e:\n",
    "    print('Log write failed:', e)\n",
    "\n",
    "if ret == 0:\n",
    "    try:\n",
    "        with open(done_marker, 'w', encoding='utf-8') as dm:\n",
    "            dm.write('ok')\n",
    "    except Exception as e:\n",
    "        print('Done marker write failed:', e)\n",
    "\n",
    "tail_snip = combined_tail[-20:]\n",
    "if tail_snip:\n",
    "    print('--- tail (last 20 lines) ---')\n",
    "    for ln in tail_snip:\n",
    "        print(ln)\n",
    "    print('--- end tail ---')\n",
    "\n",
    "print({'shard': base, 'exit': ret, 'sec': dur, 'moved_jsons': moved[:3], 'new_outputs': {'images': new_imgs, 'seg': new_segs, 'inst': new_insts}})\n",
    "]},{\n",
    ":\n",
    ",\n",
    ":{\n",
    ":\n",
    "},\n",
    ":[\n",
    "7\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "{OUT_ROOT}/images/*.png\"))\n",
    "seg_count = len(glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\"))\n",
    "inst_count = len(glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\"))\n",
    "json_files = sorted(glob.glob(f\"{OUT_ROOT}/*_train.json\") + glob.glob(f\"{OUT_ROOT}/*_test.json\"))\n",
    "print({'images': img_count, 'segmentation': seg_count, 'instance': inst_count, 'json_total': len(json_files), 'json_sample': [os.path.basename(x) for x in json_files[:5]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 8\n",
    "\n",
    "# Log özet ve ilerleme\n",
    "import os, glob\n",
    "LOG_DIR = os.path.join(OUT_ROOT, 'logs')\n",
    "run_csv = os.path.join(LOG_DIR, 'run.csv')\n",
    "done_markers = sorted(glob.glob(os.path.join(LOG_DIR, '*.done')))\n",
    "print({'log_dir_exists': os.path.isdir(LOG_DIR), 'done_markers': len(done_markers), 'done_samples': [os.path.basename(x) for x in done_markers[:5]]})\n",
    "if os.path.isfile(run_csv):\n",
    "    with open(run_csv, 'r', encoding='utf-8') as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "    print('run.csv last 10:')\n",
    "    for ln in lines[-10:]:\n",
    "        print('  ', ln)\n",
    "else:\n",
    "    print('run.csv yok')\n",
    "\n",
    "print({'TMN_TIMEOUT_SEC': os.environ.get('TMN_TIMEOUT_SEC', '3600'), 'TMN_HEARTBEAT_SEC': os.environ.get('TMN_HEARTBEAT_SEC', '30')})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31ae3fd",
   "metadata": {},
   "source": [
    "# Generate DS2 Dense TMN (Google Colab)\n",
    "\n",
    "This notebook sets up a Colab GPU runtime, installs dependencies, mounts Google Drive, and runs the TMN symbol placement to generate DS2 Dense TMN dataset outputs directly in Drive. It does not perform Mask R-CNN training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Runtime and GPU Check\n",
    "import os, sys, platform, time, json\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"In Colab: {IN_COLAB}\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"Torch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "except Exception as e:\n",
    "    print('Torch import failed, will install below.', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "import sys\n",
    "def pip_install(pkgs):\n",
    "    import subprocess\n",
    "    cmd = [sys.executable, '-m', 'pip', 'install', '-U'] + pkgs\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "try:\n",
    "    import torch, torchvision\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import PIL\n",
    "    import pycocotools\n",
    "    print('Dependencies already installed.')\n",
    "except Exception:\n",
    "    pkgs = [\n",
    "        'torch', 'torchvision', 'torchaudio',\n",
    "        'numpy', 'pandas', 'matplotlib', 'pillow',\n",
    "        'pycocotools',\n",
    "        'tqdm',\n",
    "    ]\n",
    "    pip_install(pkgs)\n",
    "    import torch, torchvision\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import PIL\n",
    "    import pycocotools\n",
    "print('torch:', torch.__version__, 'torchvision:', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580747c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Drive\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_DIR = '/content/drive/MyDrive/omr_copilot'\n",
    "else:\n",
    "    import os\n",
    "    BASE_DIR = os.path.expanduser('~/omr_copilot_colab')\n",
    "print('BASE_DIR:', BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1492f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables and Paths\n",
    "from pathlib import Path\n",
    "import os\n",
    "DATA_DIR = Path(BASE_DIR) / 'datasets' / 'ds2_dense_tmn'\n",
    "OUTPUT_DIR = Path(BASE_DIR) / 'outputs' / 'mask_rcnn'\n",
    "for p in [DATA_DIR, OUTPUT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['OMR_BASE_DIR'] = str(BASE_DIR)\n",
    "os.environ['OMR_DATA_DIR'] = str(DATA_DIR)\n",
    "os.environ['OMR_OUTPUT_DIR'] = str(OUTPUT_DIR)\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aab0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download or Upload Data\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print('Option A: Upload via files.upload()')\n",
    "    from google.colab import files\n",
    "    # Uncomment to use manual upload\n",
    "    # uploaded = files.upload()\n",
    "    print('Option B: Use Drive: Place zip at', DATA_DIR)\n",
    "else:\n",
    "    print('Running outside Colab; ensure dataset exists at', DATA_DIR)\n",
    "from pathlib import Path\n",
    "ZIP_PATH = DATA_DIR / 'ds2_dense_tmn.zip'\n",
    "EXTRACT_DIR = DATA_DIR\n",
    "if ZIP_PATH.exists():\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
    "        zf.extractall(EXTRACT_DIR)\n",
    "        print('Extracted to', EXTRACT_DIR)\n",
    "# Verify structure\n",
    "expected_dirs = ['images', 'segmentation', 'instance', 'jsonlar']\n",
    "for d in expected_dirs:\n",
    "    p = EXTRACT_DIR / d\n",
    "    print(d, 'exists:', p.exists(), 'path:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc138d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Benchmark: CPU vs GPU\n",
    "import torch, time\n",
    "x = torch.randn((2048, 2048))\n",
    "def bench(device):\n",
    "    t0 = time.time()\n",
    "    y = x.to(device) * x.to(device)\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    return time.time()-t0\n",
    "cpu_t = bench(torch.device('cpu'))\n",
    "gpu_t = None\n",
    "if torch.cuda.is_available():\n",
    "    gpu_t = bench(torch.device('cuda'))\n",
    "print({'cpu_sec': cpu_t, 'gpu_sec': gpu_t})\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU mem (allocated):', torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea35872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Outputs to Drive\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "OUT = Path(OUTPUT_DIR)\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "df = pd.DataFrame({'metric': ['cpu_sec','gpu_sec'], 'value': [0.0, 0.0]})\n",
    "csv_path = OUT / 'benchmark.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Wrote', csv_path, 'exists:', csv_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo from GitHub (optional if already in Drive)\n",
    "import os, sys, subprocess, pathlib\n",
    "REPO_URL = 'https://github.com/mtalhabalci/omr_tmn.git'\n",
    "WORKDIR = '/content/omr_tmn'\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.isdir(WORKDIR):\n",
    "        print('Cloning repo...')\n",
    "        subprocess.check_call(['git','clone',REPO_URL, WORKDIR])\n",
    "    else:\n",
    "        print('Repo exists; pulling latest...')\n",
    "        subprocess.call(['bash','-lc', f'cd {WORKDIR} && git pull --rebase'])\n",
    "    %cd {WORKDIR}\n",
    "else:\n",
    "    print('Not in Colab; skipping clone and cd.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Drive paths for DS2 Dense (source) and DS2 Dense TMN (output)\n",
    "SRC_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense'\n",
    "OUT_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn'\n",
    "JSON_GLOB = f\"{SRC_ROOT}/deepscores_*.json\"  # matches train+test\n",
    "SRC_IMAGES = f\"{SRC_ROOT}/images\"\n",
    "print({'SRC_ROOT': SRC_ROOT, 'OUT_ROOT': OUT_ROOT, 'JSON_GLOB': JSON_GLOB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e778ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TMN placement: from-fs-missing, per-shard JSON, checkpoint flush\n",
    "import sys, subprocess, os\n",
    "cmd = [\n",
    "    sys.executable, 'src/place_tmn_batch.py',\n",
    "    '--images-dir', SRC_IMAGES,\n",
    "    '--out-root', OUT_ROOT,\n",
    "    '--json-glob', JSON_GLOB,\n",
    "    '--from-fs-missing',\n",
    "    '--checkpoint', '100',\n",
    "    '--json-out-mode', 'per-shard',\n",
    "    '--limit', '0'\n",
    "]\n",
    "print('Running:', ' '.join(cmd))\n",
    "ret = subprocess.call(cmd)\n",
    "print('Exit code:', ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "import os, glob, json\n",
    "img_count = len(glob.glob(f\"{OUT_ROOT}/images/*.png\"))\n",
    "seg_count = len(glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\"))\n",
    "inst_count = len(glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\"))\n",
    "json_files = sorted(glob.glob(f\"{OUT_ROOT}/jsonlar/*.json\"))\n",
    "print({'images': img_count, 'segmentation': seg_count, 'instance': inst_count, 'jsons': json_files[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b416228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader for DS2 Dense TMN (COCO-like)\n",
    "import json, os, glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS2TMNDataset(Dataset):\n",
    "    def __init__(self, images_dir, json_paths, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        # merge shards\n",
    "        self.images = []\n",
    "        self.ann_by_img = {}\n",
    "        for jp in json_paths:\n",
    "            with open(jp,'r',encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            imgs = data.get('images') or []\n",
    "            anns = data.get('annotations') or {}\n",
    "            if isinstance(imgs, dict):\n",
    "                imgs = list(imgs.values())\n",
    "            for im in imgs:\n",
    "                fn = im.get('filename') or im.get('file_name')\n",
    "                if not fn:\n",
    "                    continue\n",
    "                self.images.append({'id': int(im.get('id')), 'filename': fn})\n",
    "            for k,v in anns.items():\n",
    "                img_id = int(v.get('img_id'))\n",
    "                self.ann_by_img.setdefault(img_id, []).append(v)\n",
    "        # deduplicate by filename order\n",
    "        seen = set()\n",
    "        uniq = []\n",
    "        for im in self.images:\n",
    "            if im['filename'] in seen:\n",
    "                continue\n",
    "            seen.add(im['filename'])\n",
    "            uniq.append(im)\n",
    "        self.images = uniq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im = self.images[idx]\n",
    "        fn = im['filename']\n",
    "        path = os.path.join(self.images_dir, fn)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        w, h = img.size\n",
    "        # build target from annotations (boxes + labels + masks optional later)\n",
    "        anns = self.ann_by_img.get(im['id'], [])\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for a in anns:\n",
    "            b = a.get('a_bbox') or a.get('bbox')\n",
    "            cats = a.get('cat_id') or []\n",
    "            if b and len(b)>=4:\n",
    "                boxes.append([b[0], b[1], b[2], b[3]])\n",
    "                # single-category per ann\n",
    "                lab = int(cats[0]) if (isinstance(cats, list) and cats) else 0\n",
    "                labels.append(lab)\n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'image_id': torch.tensor([im['id']])\n",
    "        }\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torchvision.transforms.ToTensor()(img)\n",
    "        return img, target\n",
    "\n",
    "# Build datasets/loaders\n",
    "train_jsons = sorted(glob.glob(f\"{OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "print({'train_jsons': train_jsons[:3], 'test_jsons': test_jsons[:3]})\n",
    "train_ds = DS2TMNDataset(images_dir=SRC_IMAGES, json_paths=train_jsons)\n",
    "test_ds = DS2TMNDataset(images_dir=SRC_IMAGES, json_paths=test_jsons)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Auto batch size based on GPU\n",
    "import torch\n",
    "bs = 4\n",
    "if torch.cuda.is_available():\n",
    "    name = torch.cuda.get_device_name(0).lower()\n",
    "    if 'a100' in name or 'l4' in name or 'v100' in name:\n",
    "        bs = 8\n",
    "    elif 't4' in name or 'p100' in name:\n",
    "        bs = 4\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "print({'batch_size': bs, 'train_len': len(train_ds), 'test_len': len(test_ds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask R-CNN model setup\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "num_classes = 1 + 8  # background + 8 TMN cats\n",
    "model = maskrcnn_resnet50_fpn(weights=None)\n",
    "# Replace box head\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "# Replace mask head\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print('Model ready on', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with AMP + checkpoints to Drive\n",
    "import torch, time, os\n",
    "from torch.optim import SGD\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "EPOCHS = 3\n",
    "lr = 0.005\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "optimizer = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "CKPT_DIR = os.path.join(OUT_ROOT, 'checkpoints')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "    total_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += losses.item()\n",
    "    dur = time.time()-t0\n",
    "    avg = total_loss / max(1, len(train_loader))\n",
    "    print({'epoch': epoch+1, 'loss': round(avg,3), 'sec': round(dur,1)})\n",
    "    # Save checkpoint\n",
    "    ckpt_path = os.path.join(CKPT_DIR, f'maskrcnn_epoch{epoch+1}.pt')\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+1}, ckpt_path)\n",
    "    print('Saved', ckpt_path)\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick eval: run on few test samples and visualize boxes\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def run_eval(n=3):\n",
    "    cnt = 0\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "        for img, out in zip(images, outputs):\n",
    "            if cnt>=n:\n",
    "                return\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "            ax.imshow(img.permute(1,2,0).cpu().numpy())\n",
    "            boxes = out['boxes'].cpu().numpy()\n",
    "            scores = out['scores'].cpu().numpy()\n",
    "            for b,s in zip(boxes, scores):\n",
    "                if s<0.5:\n",
    "                    continue\n",
    "                x1,y1,x2,y2 = b\n",
    "                ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, color='lime', linewidth=2))\n",
    "            ax.set_title(f\"detections (>=0.5), {len(boxes)} boxes\")\n",
    "            plt.show()\n",
    "            cnt += 1\n",
    "\n",
    "run_eval(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count files under DS2 Complete (images/segmentation/instance + JSON train/test)\n",
    "import os, glob, json\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete'\n",
    "IMAGES_DIR = os.path.join(ROOT, 'images')\n",
    "SEG_DIR = os.path.join(ROOT, 'segmentation')\n",
    "INST_DIR = os.path.join(ROOT, 'instance')\n",
    "JSON_DIR = os.path.join(ROOT, 'jsonlar')\n",
    "\n",
    "# Collect files\n",
    "images = sorted(glob.glob(os.path.join(IMAGES_DIR, '*.png')))\n",
    "segs = sorted(glob.glob(os.path.join(SEG_DIR, '*.png')))\n",
    "insts = sorted(glob.glob(os.path.join(INST_DIR, '*.png')))\n",
    "json_all = sorted(glob.glob(os.path.join(JSON_DIR, '*.json')))\n",
    "json_train = [p for p in json_all if ('train' in os.path.basename(p).lower())]\n",
    "json_test = [p for p in json_all if ('test' in os.path.basename(p).lower())]\n",
    "\n",
    "# Derive base names for consistency checks\n",
    "base_images = {os.path.splitext(os.path.basename(p))[0] for p in images}\n",
    "base_segs = {os.path.basename(p).replace('_seg.png','') for p in segs}\n",
    "base_insts = {os.path.basename(p).replace('_inst.png','') for p in insts}\n",
    "\n",
    "missing_seg = sorted(list(base_images - base_segs))\n",
    "missing_inst = sorted(list(base_images - base_insts))\n",
    "extra_seg = sorted(list(base_segs - base_images))\n",
    "extra_inst = sorted(list(base_insts - base_images))\n",
    "\n",
    "print({'ROOT': ROOT})\n",
    "print({'images_png': len(images), 'segmentation_png': len(segs), 'instance_png': len(insts)})\n",
    "print({'json_total': len(json_all), 'json_train_files': len(json_train), 'json_test_files': len(json_test)})\n",
    "\n",
    "# Quick consistency report\n",
    "print({'images_vs_seg_equal': len(base_images)==len(base_segs) and (not missing_seg) and (not extra_seg),\n",
    "       'images_vs_inst_equal': len(base_images)==len(base_insts) and (not missing_inst) and (not extra_inst)})\n",
    "\n",
    "# Show small samples of mismatches if any\n",
    "if missing_seg:\n",
    "    print('Missing segmentation for first 5 images:', missing_seg[:5])\n",
    "if missing_inst:\n",
    "    print('Missing instance for first 5 images:', missing_inst[:5])\n",
    "if extra_seg:\n",
    "    print('Segmentation without matching image (first 5):', extra_seg[:5])\n",
    "if extra_inst:\n",
    "    print('Instance without matching image (first 5):', extra_inst[:5])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

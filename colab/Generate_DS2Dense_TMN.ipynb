{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31ae3fd",
   "metadata": {},
   "source": [
    "## Hücre 1\n",
    "\n",
    "# Generate DS2 Complete TMN (Google Colab)\n",
    "\n",
    "This notebook only generates the DS2 Complete TMN outputs directly on Google Drive. Code is cloned from GitHub into /content/omr_tmn, dataset lives on Google Drive at SRC_ROOT. We run shard-wise TMN placement and verify counts. There is no training, no CUDA usage, and no Mask R-CNN code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580747c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 2\n",
    "\n",
    "# Connect to Google Drive\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping Drive mount.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 3\n",
    "\n",
    "# Clone repo from GitHub (optional if already in Drive)\n",
    "import os, sys, subprocess, pathlib\n",
    "REPO_URL = 'https://github.com/mtalhabalci/omr_tmn.git'\n",
    "WORKDIR = '/content/omr_tmn'\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.isdir(WORKDIR):\n",
    "        print('Cloning repo...')\n",
    "        subprocess.check_call(['git','clone',REPO_URL, WORKDIR])\n",
    "    else:\n",
    "        print('Repo exists; pulling latest...')\n",
    "        subprocess.call(['bash','-lc', f'cd {WORKDIR} && git pull --rebase'])\n",
    "    %cd {WORKDIR}\n",
    "else:\n",
    "    print('Not in Colab; skipping clone and cd.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 4\n",
    "\n",
    "# Configure Drive paths for DS2 Complete (source) and DS2 Complete TMN (output)\n",
    "SRC_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete'\n",
    "OUT_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete_tmn'\n",
    "SRC_IMAGES = f\"{SRC_ROOT}/images\"\n",
    "print({'SRC_ROOT': SRC_ROOT, 'OUT_ROOT': OUT_ROOT, 'SRC_IMAGES': SRC_IMAGES})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e778ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 5\n",
    "\n",
    "# Run TMN placement on DS2 Complete: shard-wise, resume-safe, JSONs at OUT_ROOT root\n",
    "import sys, subprocess, os, glob, time\n",
    "\n",
    "# Ensure output structure exists (mirror source)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'segmentation'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'instance'), exist_ok=True)\n",
    "LOG_DIR = os.path.join(OUT_ROOT, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Collect JSON shards at SRC_ROOT root (not under jsonlar)\n",
    "train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')))\n",
    "test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "shards = train_shards + test_shards\n",
    "print({'shard_count': len(shards), 'sample_shards': [os.path.basename(x) for x in shards[:5]]})\n",
    "\n",
    "# Process each shard; skip if .done exists; within shard, skip existing files via --from-fs-missing\n",
    "for jp in shards:\n",
    "    base = os.path.basename(jp)\n",
    "    done_marker = os.path.join(LOG_DIR, base + '.done')\n",
    "    if os.path.exists(done_marker):\n",
    "        print('Skipping shard, already done:', base)\n",
    "        continue\n",
    "    t0 = time.time()\n",
    "    cmd = [\n",
    "        sys.executable, 'src/place_tmn_batch.py',\n",
    "        '--images-dir', SRC_IMAGES,\n",
    "        '--out-root', OUT_ROOT,\n",
    "        '--json-file', jp,\n",
    "        '--from-fs-missing',\n",
    "        '--checkpoint', '200',\n",
    "        '--json-out-mode', 'per-shard'\n",
    "    ]\n",
    "    print('Running shard:', base)\n",
    "    print('Command:', ' '.join(cmd))\n",
    "    ret = subprocess.call(cmd)\n",
    "\n",
    "    # If the placer wrote JSONs under OUT_ROOT/jsonlar, move them to OUT_ROOT root\n",
    "    moved = []\n",
    "    jsonlar_dir = os.path.join(OUT_ROOT, 'jsonlar')\n",
    "    if os.path.isdir(jsonlar_dir):\n",
    "        for f in glob.glob(os.path.join(jsonlar_dir, '*.json')):\n",
    "            dest = os.path.join(OUT_ROOT, os.path.basename(f))\n",
    "            try:\n",
    "                os.replace(f, dest)\n",
    "                moved.append(os.path.basename(f))\n",
    "            except Exception as e:\n",
    "                print('Move failed', f, '->', dest, e)\n",
    "        # Remove empty jsonlar folder if now empty\n",
    "        try:\n",
    "            if not os.listdir(jsonlar_dir):\n",
    "                os.rmdir(jsonlar_dir)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    dur = round(time.time() - t0, 1)\n",
    "    # Append per-shard log line\n",
    "    try:\n",
    "        with open(os.path.join(LOG_DIR, 'run.csv'), 'a', encoding='utf-8') as lf:\n",
    "            lf.write(f\"{base},{ret},{dur},{len(moved)}\\n\")\n",
    "    except Exception as e:\n",
    "        print('Log write failed:', e)\n",
    "\n",
    "    if ret == 0:\n",
    "        try:\n",
    "            with open(done_marker, 'w', encoding='utf-8') as dm:\n",
    "                dm.write('ok')\n",
    "        except Exception as e:\n",
    "            print('Done marker write failed:', e)\n",
    "\n",
    "    print({'shard': base, 'exit': ret, 'sec': dur, 'moved_jsons': moved[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 6\n",
    "\n",
    "# Verify outputs for DS2 Complete TMN\n",
    "import os, glob, json\n",
    "\n",
    "img_count = len(glob.glob(f\"{OUT_ROOT}/images/*.png\"))\n",
    "seg_count = len(glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\"))\n",
    "inst_count = len(glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\"))\n",
    "# JSONs are expected at OUT_ROOT root (no jsonlar folder)\n",
    "json_files = sorted(glob.glob(f\"{OUT_ROOT}/*_train.json\") + glob.glob(f\"{OUT_ROOT}/*_test.json\"))\n",
    "print({'images': img_count, 'segmentation': seg_count, 'instance': inst_count, 'jsons_sample': [os.path.basename(x) for x in json_files[:5]], 'json_total': len(json_files)})\n",
    "\n",
    "# Optional: consistency by basename\n",
    "basename_noext = lambda p: os.path.splitext(os.path.basename(p))[0]\n",
    "base_images = {basename_noext(p) for p in glob.glob(f\"{OUT_ROOT}/images/*.png\")}\n",
    "base_segs = {os.path.basename(p).replace('_seg.png','') for p in glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\")}\n",
    "base_insts = {os.path.basename(p).replace('_inst.png','') for p in glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\")}\n",
    "\n",
    "if base_images:\n",
    "    missing_seg = sorted(list(base_images - base_segs))\n",
    "    missing_inst = sorted(list(base_images - base_insts))\n",
    "    print({'images_vs_seg_equal': len(missing_seg) == 0, 'images_vs_inst_equal': len(missing_inst) == 0})\n",
    "    if missing_seg[:5]: print('Missing segmentation (first 5):', missing_seg[:5])\n",
    "    if missing_inst[:5]: print('Missing instance (first 5):', missing_inst[:5])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

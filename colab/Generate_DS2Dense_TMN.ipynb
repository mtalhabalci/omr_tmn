{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31ae3fd",
   "metadata": {},
   "source": [
    "## Hücre 1\n",
    "\n",
    "# Generate DS2 Complete TMN (Google Colab)\n",
    "\n",
    "This notebook only generates the DS2 Complete TMN outputs directly on Google Drive. Code is cloned from GitHub into /content/omr_tmn, dataset lives on Google Drive at SRC_ROOT. We run shard-wise TMN placement and verify counts. There is no training, no CUDA usage, and no Mask R-CNN code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580747c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 2\n",
    "\n",
    "# Connect to Google Drive\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    # Use force_remount to avoid stale mounts/timeouts\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping Drive mount.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 3\n",
    "\n",
    "# Clone repo from GitHub (optional if already in Drive)\n",
    "import os, sys, subprocess, pathlib\n",
    "\n",
    "REPO_URL = 'https://github.com/mtalhabalci/omr_tmn.git'\n",
    "WORKDIR = '/content/omr_tmn'\n",
    "SCRIPT_PATH = None\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.isdir(WORKDIR):\n",
    "        print('Cloning repo...')\n",
    "        subprocess.check_call(['git','clone',REPO_URL, WORKDIR])\n",
    "    else:\n",
    "        print('Repo exists; pulling latest...')\n",
    "        subprocess.call(['bash','-lc', f'cd {WORKDIR} && git pull --rebase'])\n",
    "    # Change directory via Python for reliability\n",
    "    os.chdir(WORKDIR)\n",
    "    print('Changed dir to', os.getcwd())\n",
    "    # Prefer src/place_tmn_batch.py inside repo\n",
    "    candidate = os.path.join(WORKDIR, 'src', 'place_tmn_batch.py')\n",
    "    if os.path.isfile(candidate):\n",
    "        SCRIPT_PATH = candidate\n",
    "    else:\n",
    "        alt = os.path.join(WORKDIR, 'place_tmn_batch.py')\n",
    "        SCRIPT_PATH = alt if os.path.isfile(alt) else candidate\n",
    "    print({'SCRIPT_PATH': SCRIPT_PATH, 'exists': os.path.isfile(SCRIPT_PATH)})\n",
    "else:\n",
    "    print('Not in Colab; skipping clone and cd.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 4\n",
    "\n",
    "# Configure Drive paths for DS2 Complete (source) and DS2 Complete TMN (output)\n",
    "SRC_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete'\n",
    "OUT_ROOT = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_complete_tmn'\n",
    "SRC_IMAGES = f\"{SRC_ROOT}/images\"\n",
    "print({'SRC_ROOT': SRC_ROOT, 'OUT_ROOT': OUT_ROOT, 'SRC_IMAGES': SRC_IMAGES})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e778ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 5\n",
    "\n",
    "# Run TMN placement on DS2 Complete: shard-wise, resume-safe, JSONs at OUT_ROOT root\n",
    "import sys, subprocess, os, glob, time\n",
    "\n",
    "# Resolve script path robustly\n",
    "sp_candidates = []\n",
    "try:\n",
    "    # If set in previous cell\n",
    "    if 'SCRIPT_PATH' in globals() and isinstance(SCRIPT_PATH, str):\n",
    "        sp_candidates.append(SCRIPT_PATH)\n",
    "except Exception:\n",
    "    pass\n",
    "sp_candidates += [\n",
    "    os.path.join('/content/omr_tmn', 'src', 'place_tmn_batch.py'),\n",
    "    os.path.join('/content/omr_tmn', 'place_tmn_batch.py'),\n",
    "    'src/place_tmn_batch.py'\n",
    "]\n",
    "SCRIPT_TO_RUN = next((p for p in sp_candidates if os.path.isfile(p)), None)\n",
    "print({'SCRIPT_TO_RUN': SCRIPT_TO_RUN, 'exists': bool(SCRIPT_TO_RUN and os.path.isfile(SCRIPT_TO_RUN))})\n",
    "if not SCRIPT_TO_RUN:\n",
    "    print('ERROR: place_tmn_batch.py not found in expected locations. Check repo structure.')\n",
    "\n",
    "# Ensure output structure exists (mirror source)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'segmentation'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT, 'instance'), exist_ok=True)\n",
    "LOG_DIR = os.path.join(OUT_ROOT, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Collect JSON shards at SRC_ROOT root (not under jsonlar)\n",
    "train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')))\n",
    "test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "shards = train_shards + test_shards\n",
    "print({'shard_count': len(shards), 'sample_shards': [os.path.basename(x) for x in shards[:5]]})\n",
    "\n",
    "# Process each shard; skip if .done exists; within shard, reprocess regardless of existing outputs (force)\n",
    "for jp in shards:\n",
    "    base = os.path.basename(jp)\n",
    "    done_marker = os.path.join(LOG_DIR, base + '.done')\n",
    "    if os.path.exists(done_marker):\n",
    "        print('Skipping shard, already done:', base)\n",
    "        continue\n",
    "    t0 = time.time()\n",
    "    if SCRIPT_TO_RUN:\n",
    "        cmd = [\n",
    "            sys.executable, '-u', SCRIPT_TO_RUN,\n",
    "            '--images-dir', SRC_IMAGES,\n",
    "            '--out-root', OUT_ROOT,\n",
    "            '--json-path', jp,\n",
    "            '--checkpoint', '200',\n",
    "            '--json-out-mode', 'per-shard',\n",
    "            '--symbols-dir', '/content/omr_tmn/tmn_symbols_png',\n",
    "            '--force',\n",
    "            '--slot-w', '12',\n",
    "            '--slot-h', '36',\n",
    "            '--disable-barline-mask',\n",
    "            '--limit', '50'\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [sys.executable, '-u', '-c', \"import sys; print('script missing'); sys.exit(2)\"]\n",
    "\n",
    "    print('Running shard:', base)\n",
    "    print('Command:', ' '.join(cmd))\n",
    "\n",
    "    # Live log streaming + timeout\n",
    "    TIMEOUT_PER_SHARD = int(os.environ.get('TMN_TIMEOUT_SEC', '3600'))  # 1 hour default\n",
    "    HEARTBEAT_SEC = int(os.environ.get('TMN_HEARTBEAT_SEC', '30'))\n",
    "    last_beat = time.time()\n",
    "    combined_tail = []\n",
    "\n",
    "    ret = None\n",
    "    try:\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "        while True:\n",
    "            line = p.stdout.readline()\n",
    "            if not line:\n",
    "                if p.poll() is not None:\n",
    "                    break\n",
    "                # idle short sleep to avoid tight loop\n",
    "                time.sleep(0.2)\n",
    "                continue\n",
    "            line = line.rstrip('\\n')\n",
    "            if line:\n",
    "                print(line)\n",
    "                combined_tail.append(line)\n",
    "                if len(combined_tail) > 400:\n",
    "                    combined_tail = combined_tail[-400:]\n",
    "\n",
    "            now = time.time()\n",
    "            if now - last_beat >= HEARTBEAT_SEC:\n",
    "                elapsed = int(now - t0)\n",
    "                print(f\"[heartbeat] {base} running {elapsed}s...\")\n",
    "                last_beat = now\n",
    "\n",
    "            if now - t0 > TIMEOUT_PER_SHARD:\n",
    "                print(f\"Timeout after {TIMEOUT_PER_SHARD}s; terminating shard {base}\")\n",
    "                try:\n",
    "                    p.terminate()\n",
    "                    p.wait(timeout=10)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                try:\n",
    "                    p.kill()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                ret = 124  # conventional timeout code\n",
    "                break\n",
    "\n",
    "        if ret is None:\n",
    "            ret = p.wait()\n",
    "    except Exception as e:\n",
    "        print('Runner failed:', e)\n",
    "        ret = 2\n",
    "\n",
    "    # Always show a brief tail snippet for summary/diagnostics\n",
    "    tail_snip = combined_tail[-20:]\n",
    "    if tail_snip:\n",
    "        print('--- tail (last 20 lines) ---')\n",
    "        for ln in tail_snip:\n",
    "            print(ln)\n",
    "        print('--- end tail ---')\n",
    "\n",
    "    # If the placer wrote JSONs under OUT_ROOT/jsonlar, move them to OUT_ROOT root\n",
    "    moved = []\n",
    "    jsonlar_dir = os.path.join(OUT_ROOT, 'jsonlar')\n",
    "    if os.path.isdir(jsonlar_dir):\n",
    "        for f in glob.glob(os.path.join(jsonlar_dir, '*.json')):\n",
    "            dest = os.path.join(OUT_ROOT, os.path.basename(f))\n",
    "            try:\n",
    "                os.replace(f, dest)\n",
    "                moved.append(os.path.basename(f))\n",
    "            except Exception as e:\n",
    "                print('Move failed', f, '->', dest, e)\n",
    "        try:\n",
    "            if not os.listdir(jsonlar_dir):\n",
    "                os.rmdir(jsonlar_dir)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Quick count of newly created outputs since shard start\n",
    "    def count_new(dir_path, suffix):\n",
    "        cnt = 0\n",
    "        try:\n",
    "            for nm in os.listdir(dir_path):\n",
    "                if not nm.lower().endswith(suffix):\n",
    "                    continue\n",
    "                pth = os.path.join(dir_path, nm)\n",
    "                try:\n",
    "                    st = os.stat(pth)\n",
    "                    if st.st_mtime >= t0:\n",
    "                        cnt += 1\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        return cnt\n",
    "    new_imgs = count_new(os.path.join(OUT_ROOT, 'images'), '.png')\n",
    "    new_segs = count_new(os.path.join(OUT_ROOT, 'segmentation'), '_seg.png')\n",
    "    new_insts = count_new(os.path.join(OUT_ROOT, 'instance'), '_inst.png')\n",
    "\n",
    "    dur = round(time.time() - t0, 1)\n",
    "    try:\n",
    "        with open(os.path.join(LOG_DIR, 'run.csv'), 'a', encoding='utf-8') as lf:\n",
    "            lf.write(f\"{base},{ret},{dur},{len(moved)}\\n\")\n",
    "    except Exception as e:\n",
    "        print('Log write failed:', e)\n",
    "\n",
    "    if ret == 0:\n",
    "        try:\n",
    "            with open(done_marker, 'w', encoding='utf-8') as dm:\n",
    "                dm.write('ok')\n",
    "        except Exception as e:\n",
    "            print('Done marker write failed:', e)\n",
    "\n",
    "    print({'shard': base, 'exit': ret, 'sec': dur, 'moved_jsons': moved[:3], 'new_outputs': {'images': new_imgs, 'seg': new_segs, 'inst': new_insts}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 6\n",
    "\n",
    "# Verify outputs for DS2 Complete TMN\n",
    "import os, glob, json\n",
    "\n",
    "img_count = len(glob.glob(f\"{OUT_ROOT}/images/*.png\"))\n",
    "seg_count = len(glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\"))\n",
    "inst_count = len(glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\"))\n",
    "# JSONs are expected at OUT_ROOT root (no jsonlar folder)\n",
    "json_files = sorted(glob.glob(f\"{OUT_ROOT}/*_train.json\") + glob.glob(f\"{OUT_ROOT}/*_test.json\"))\n",
    "print({'images': img_count, 'segmentation': seg_count, 'instance': inst_count, 'jsons_sample': [os.path.basename(x) for x in json_files[:5]], 'json_total': len(json_files)})\n",
    "\n",
    "# Optional: consistency by basename\n",
    "basename_noext = lambda p: os.path.splitext(os.path.basename(p))[0]\n",
    "base_images = {basename_noext(p) for p in glob.glob(f\"{OUT_ROOT}/images/*.png\")}\n",
    "base_segs = {os.path.basename(p).replace('_seg.png','') for p in glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\")}\n",
    "base_insts = {os.path.basename(p).replace('_inst.png','') for p in glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\")}\n",
    "\n",
    "if base_images:\n",
    "    missing_seg = sorted(list(base_images - base_segs))\n",
    "    missing_inst = sorted(list(base_images - base_insts))\n",
    "    print({'images_vs_seg_equal': len(missing_seg) == 0, 'images_vs_inst_equal': len(missing_inst) == 0})\n",
    "    if missing_seg[:5]: print('Missing segmentation (first 5):', missing_seg[:5])\n",
    "    if missing_inst[:5]: print('Missing instance (first 5):', missing_inst[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55331d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 7\n",
    "\n",
    "# Inspect logs and shard detection to diagnose quick finish\n",
    "import os, glob, csv\n",
    "print({'SRC_ROOT': SRC_ROOT, 'OUT_ROOT': OUT_ROOT})\n",
    "\n",
    "# Detect shards with primary and fallback patterns\n",
    "train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')))\n",
    "test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "if not train_shards and not test_shards:\n",
    "    train_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*train*.json')))\n",
    "    test_shards = sorted(glob.glob(os.path.join(SRC_ROOT, '*test*.json')))\n",
    "shards = train_shards + test_shards\n",
    "print({'shard_count': len(shards), 'sample_shards': [os.path.basename(x) for x in shards[:5]]})\n",
    "\n",
    "# Logs summary\n",
    "LOG_DIR = os.path.join(OUT_ROOT, 'logs')\n",
    "run_csv = os.path.join(LOG_DIR, 'run.csv')\n",
    "done_markers = sorted(glob.glob(os.path.join(LOG_DIR, '*.done')))\n",
    "print({'log_dir_exists': os.path.isdir(LOG_DIR), 'done_markers': len(done_markers), 'done_samples': [os.path.basename(x) for x in done_markers[:5]]})\n",
    "\n",
    "tail = []\n",
    "stats = {'total_lines': 0, 'ret0': 0, 'ret_nonzero': 0}\n",
    "if os.path.isfile(run_csv):\n",
    "    with open(run_csv, 'r', encoding='utf-8') as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "    stats['total_lines'] = len(lines)\n",
    "    tail = lines[-10:]\n",
    "    for ln in lines:\n",
    "        # expected format: base,ret,dur,movedCount\n",
    "        parts = ln.split(',')\n",
    "        if len(parts) >= 4:\n",
    "            try:\n",
    "                ret = int(parts[1])\n",
    "                stats['ret0'] += 1 if ret == 0 else 0\n",
    "                stats['ret_nonzero'] += 1 if ret != 0 else 0\n",
    "            except:\n",
    "                pass\n",
    "print({'run_csv_exists': os.path.isfile(run_csv), 'stats': stats})\n",
    "print('run.csv last 10 lines:')\n",
    "for ln in tail:\n",
    "    print('  ', ln)\n",
    "\n",
    "# Quick output presence check\n",
    "img_count = len(glob.glob(f\"{OUT_ROOT}/images/*.png\"))\n",
    "seg_count = len(glob.glob(f\"{OUT_ROOT}/segmentation/*_seg.png\"))\n",
    "inst_count = len(glob.glob(f\"{OUT_ROOT}/instance/*_inst.png\"))\n",
    "json_files = sorted(glob.glob(f\"{OUT_ROOT}/*_train.json\") + glob.glob(f\"{OUT_ROOT}/*_test.json\"))\n",
    "print({'images': img_count, 'segmentation': seg_count, 'instance': inst_count, 'json_total': len(json_files), 'json_samples': [os.path.basename(x) for x in json_files[:5]]})\n",
    "\n",
    "# Common causes summary hints\n",
    "if len(shards) == 0:\n",
    "    print('Hint: No shards detected at SRC_ROOT. Check JSON naming/patterns and SRC_ROOT path.')\n",
    "elif len(done_markers) == len(shards):\n",
    "    print('Hint: All shards show as done; the runner skipped them. Delete .done markers to re-run a shard if needed.')\n",
    "elif stats['ret0'] == 0 and stats['total_lines'] > 0:\n",
    "    print('Hint: Non-zero return codes; check repo availability or src/place_tmn_batch.py path.')\n",
    "else:\n",
    "    print('Hint: If durations are very small and moved_jsons=0, there might be nothing new to process (already placed).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 8\n",
    "\n",
    "# TMN sembolleri ve ilerleme loglarını kontrol et\n",
    "import os, glob, json, time\n",
    "\n",
    "SYM_DIR = '/content/omr_tmn/tmn_symbols_png'\n",
    "print({'symbols_dir': SYM_DIR, 'exists': os.path.isdir(SYM_DIR)})\n",
    "if os.path.isdir(SYM_DIR):\n",
    "    try:\n",
    "        names = [n for n in os.listdir(SYM_DIR) if n.lower().endswith('.png')]\n",
    "        print({'symbol_png_count': len(names), 'samples': sorted(names)[:8]})\n",
    "    except Exception as e:\n",
    "        print('Symbols listing failed:', e)\n",
    "else:\n",
    "    print('Warning: TMN sembol klasörü yok; yerleştirme olmaz. Klasörü kontrol edin.')\n",
    "\n",
    "# Çıktı klasörlerinde son bir saat içinde üretilen dosya sayısı\n",
    "OUT_IMAGES = os.path.join(OUT_ROOT, 'images')\n",
    "OUT_SEG = os.path.join(OUT_ROOT, 'segmentation')\n",
    "OUT_INST = os.path.join(OUT_ROOT, 'instance')\n",
    "cutoff = time.time() - 3600  # son 1 saat\n",
    "\n",
    "def count_recent(dir_path, suffix=None):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for nm in os.listdir(dir_path):\n",
    "            if suffix and not nm.lower().endswith(suffix):\n",
    "                continue\n",
    "            p = os.path.join(dir_path, nm)\n",
    "            try:\n",
    "                if os.stat(p).st_mtime >= cutoff:\n",
    "                    cnt += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "print({'recent_outputs_last_1h': {\n",
    "    'images': count_recent(OUT_IMAGES, '.png'),\n",
    "    'segmentation': count_recent(OUT_SEG, '_seg.png'),\n",
    "    'instance': count_recent(OUT_INST, '_inst.png')\n",
    "}})\n",
    "\n",
    "# Progress log (jsonlar/progress.jsonl) son 10 kayıt\n",
    "PROG = os.path.join(OUT_ROOT, 'jsonlar', 'progress.jsonl')\n",
    "print({'progress_log_exists': os.path.isfile(PROG), 'path': PROG})\n",
    "if os.path.isfile(PROG):\n",
    "    try:\n",
    "        with open(PROG, 'r', encoding='utf-8') as f:\n",
    "            lines = [ln.strip() for ln in f if ln.strip()]\n",
    "        tail = lines[-10:]\n",
    "        print('progress.jsonl last 10:')\n",
    "        for ln in tail:\n",
    "            print('  ', ln)\n",
    "    except Exception as e:\n",
    "        print('Progress read failed:', e)\n",
    "\n",
    "# Ortam değişkenleri (timeout/heartbeat)\n",
    "import os\n",
    "print({'TMN_TIMEOUT_SEC': os.environ.get('TMN_TIMEOUT_SEC', '3600'), 'TMN_HEARTBEAT_SEC': os.environ.get('TMN_HEARTBEAT_SEC', '30')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e26b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 9\n",
    "\n",
    "# DS2 shard JSON içeriğini doğrula: kategori isimleri, örnek annotation'lar ve filename -> dosya var mı\n",
    "import os, json, glob\n",
    "\n",
    "sample_jsons = sorted(glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_train.json')) + glob.glob(os.path.join(SRC_ROOT, 'deepscores-complete-*_test.json')))\n",
    "print({'json_count': len(sample_jsons), 'first': os.path.basename(sample_jsons[0]) if sample_jsons else None})\n",
    "\n",
    "if sample_jsons:\n",
    "    jp = sample_jsons[0]\n",
    "    with open(jp, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    cats = data.get('categories') or {}\n",
    "    cat_names = []\n",
    "    for k, v in cats.items():\n",
    "        nm = v.get('name') if isinstance(v, dict) else None\n",
    "        if isinstance(nm, str):\n",
    "            cat_names.append(nm.lower())\n",
    "    cat_names = sorted(set(cat_names))\n",
    "    print({'unique_category_names_count': len(cat_names), 'has_notehead': any('notehead' in n for n in cat_names), 'has_rest': any('rest' in n for n in cat_names), 'has_flag': any('flag' in n for n in cat_names), 'has_accidental': any('accidental' in n for n in cat_names)})\n",
    "\n",
    "    imgs = data.get('images') or []\n",
    "    if isinstance(imgs, dict):\n",
    "        imgs = list(imgs.values())\n",
    "    samples = imgs[:10]\n",
    "    exists = []\n",
    "    for im in samples:\n",
    "        fn = im.get('filename') or im.get('file_name')\n",
    "        p = os.path.join(SRC_IMAGES, fn) if fn else None\n",
    "        exists.append({'filename': fn, 'exists': os.path.isfile(p)})\n",
    "    print({'image_samples_exists': exists})\n",
    "\n",
    "    anns = data.get('annotations') or []\n",
    "    if isinstance(anns, dict):\n",
    "        anns = list(anns.values())\n",
    "    # İlk 50 annotation içinden notehead içerenleri say\n",
    "    def ann_names(a):\n",
    "        cats = a.get('cat_id') or a.get('category_ids') or []\n",
    "        ids = []\n",
    "        if isinstance(cats, (list, tuple)):\n",
    "            for c in cats:\n",
    "                try:\n",
    "                    ids.append(int(c))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        elif isinstance(cats, str):\n",
    "            try:\n",
    "                ids.append(int(cats))\n",
    "            except Exception:\n",
    "                pass\n",
    "        # id->name map\n",
    "        id2name = {}\n",
    "        for k, v in (data.get('categories') or {}).items():\n",
    "            try:\n",
    "                cid = int(k)\n",
    "            except Exception:\n",
    "                continue\n",
    "            nm = v.get('name') if isinstance(v, dict) else None\n",
    "            if isinstance(nm, str):\n",
    "                id2name[cid] = nm.lower()\n",
    "        return [id2name.get(ci, str(ci)) for ci in ids]\n",
    "\n",
    "    notehead_anns = 0\n",
    "    for a in anns[:2000]:  # ilk 2000'de arayalım\n",
    "        names = ann_names(a)\n",
    "        if any('notehead' in n for n in names):\n",
    "            notehead_anns += 1\n",
    "    print({'notehead_annotations_in_first_2000': notehead_anns})\n",
    "else:\n",
    "    print('Uyarı: SRC_ROOT altında shard JSON bulunamadı.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 10\n",
    "\n",
    "# place_tmn_batch.py içine barline mask devre dışı bırakma bayrağı ekle\n",
    "import os\n",
    "SCRIPT_FILE = '/content/omr_tmn/src/place_tmn_batch.py'\n",
    "print({'script_path': SCRIPT_FILE, 'exists': os.path.isfile(SCRIPT_FILE)})\n",
    "if not os.path.isfile(SCRIPT_FILE):\n",
    "    print('Uyarı: Script bulunamadı; Hücre 3 ve script yolu çıktısını kontrol edin.')\n",
    "else:\n",
    "    with open(SCRIPT_FILE, 'r', encoding='utf-8') as f:\n",
    "        src = f.read()\n",
    "    changed = False\n",
    "    # Global değişken ekle\n",
    "    if 'BARLINE_MASK_DISABLED' not in src:\n",
    "        src = src.replace('from PIL import Image, ImageDraw,\\nImageFilter',\n",
    "                          'from PIL import Image, ImageDraw,\\nImageFilter\\n\\nBARLINE_MASK_DISABLED = False')\n",
    "        changed = True\n",
    "    # Argparse bayrağı ekle\n",
    "    if '--disable-barline-mask' not in src:\n",
    "        src = src.replace(\n",
    "            \"ap.add_argument('--json-out-mode', type=str, default='single', choices=['single','per-shard'],\\nhelp='Write a single merged JSON or one per input shard (when using\\njson-glob)')\",\n",
    "            \"ap.add_argument('--json-out-mode', type=str, default='single', choices=['single','per-shard'],\\nhelp='Write a single merged JSON or one per input shard (when using\\njson-glob)')\\n    ap.add_argument('--disable-barline-mask', dest='disable_barline_mask', action='store_true', help='Disable barline overlap masking')\"\n",
    "        )\n",
    "        changed = True\n",
    "    # Argları parse ettikten sonra global ayarla\n",
    "    if 'disable_barline_mask' in src and 'BARLINE_MASK_DISABLED = True' not in src:\n",
    "        src = src.replace(\n",
    "            'args = ap.parse_args()',\n",
    "            \"args = ap.parse_args()\\n\\n    # Apply disable barline mask\\n    global BARLINE_MASK_DISABLED\\n    if getattr(args, 'disable_barline_mask', False):\\n        BARLINE_MASK_DISABLED = True\"\n",
    "        )\n",
    "        changed = True\n",
    "    # process_one içinde bar_mask seçimini güncelle\n",
    "    pattern = \"bar_mask = load_barline_mask_for_image(fname, '#00acc6')\"\n",
    "    replacement = \"bar_mask = None if BARLINE_MASK_DISABLED else load_barline_mask_for_image(fname, '#00acc6')\"\n",
    "    if pattern in src:\n",
    "        src = src.replace(pattern, replacement)\n",
    "        changed = True\n",
    "    if changed:\n",
    "        with open(SCRIPT_FILE, 'w', encoding='utf-8') as f:\n",
    "            f.write(src)\n",
    "        print('Patch uygulandı: disable-barline-mask bayrağı eklendi.')\n",
    "    else:\n",
    "        print('Patch gerekli değil: değişiklikler zaten mevcut görünüyor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b22964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 10\n",
    "# Patcher: Add --disable-barline-mask flag support in src/place_tmn_batch.py\n",
    "# - Adds global toggle BARLINE_MASK_DISABLED\n",
    "# - Adds argparse option --disable-barline-mask\n",
    "# - Wires logic so barline mask can be bypassed safely\n",
    "import os, re\n",
    "\n",
    "candidates = [\n",
    "    os.path.join('/content/omr_tmn', 'src', 'place_tmn_batch.py'),\n",
    "    os.path.join('/content/omr_tmn', 'place_tmn_batch.py'),\n",
    "    'src/place_tmn_batch.py'\n",
    "]\n",
    "script_path = next((p for p in candidates if os.path.isfile(p)), None)\n",
    "print({'patch_target': script_path, 'exists': bool(script_path and os.path.isfile(script_path))})\n",
    "if not script_path:\n",
    "    raise FileNotFoundError('place_tmn_batch.py not found in expected locations')\n",
    "\n",
    "with open(script_path, 'r', encoding='utf-8') as f:\n",
    "    src = f.read()\n",
    "\n",
    "changed = False\n",
    "\n",
    "# 1) Insert global BARLINE_MASK_DISABLED after imports if missing\n",
    "if 'BARLINE_MASK_DISABLED' not in src:\n",
    "    lines = src.splitlines(True)\n",
    "    last_import_idx = -1\n",
    "    for i, ln in enumerate(lines):\n",
    "        if ln.strip().startswith('import ') or ln.strip().startswith('from '):\n",
    "            last_import_idx = i\n",
    "    insert_line = \"\\nBARLINE_MASK_DISABLED = False\\n\"\n",
    "    if last_import_idx >= 0:\n",
    "        lines.insert(last_import_idx + 1, insert_line)\n",
    "        src = ''.join(lines)\n",
    "        changed = True\n",
    "\n",
    "# 2) Ensure argparse flag exists\n",
    "if '--disable-barline-mask' not in src:\n",
    "    # Find parser initialization\n",
    "    m = re.search(r\"parser\\s*=\\s*argparse\\.ArgumentParser\\([^\\)]*\\)\\s*\\n\", src)\n",
    "    insert_point = m.end() if m else None\n",
    "    if insert_point is None:\n",
    "        # fallback: after first import argparse\n",
    "        m2 = re.search(r\"import\\s+argparse\\s*\\n\", src)\n",
    "        insert_point = m2.end() if m2 else 0\n",
    "    flag_line = \"parser.add_argument('--disable-barline-mask', action='store_true', help='Disable barline masking during placement')\\n\"\n",
    "    src = src[:insert_point] + flag_line + src[insert_point:]\n",
    "    changed = True\n",
    "\n",
    "# 3) Wire args to global toggle\n",
    "if 'BARLINE_MASK_DISABLED = args.disable_barline_mask' not in src:\n",
    "    m = re.search(r\"args\\s*=\\s*parser\\.parse_args\\([^\\)]*\\)\\s*\\n\", src)\n",
    "    if m:\n",
    "        ip = m.end()\n",
    "        wire = \"BARLINE_MASK_DISABLED = getattr(args, 'disable_barline_mask', False)\\n\"\n",
    "        src = src[:ip] + wire + src[ip:]\n",
    "        changed = True\n",
    "\n",
    "# 4) Respect global in barline mask assignment\n",
    "if 'BARLINE_MASK_DISABLED' in src and 'if BARLINE_MASK_DISABLED:' not in src:\n",
    "    new_lines = []\n",
    "    for ln in src.splitlines():\n",
    "        new_lines.append(ln)\n",
    "        if ln.strip().startswith('bar_mask') and '=' in ln:\n",
    "            new_lines.append('if BARLINE_MASK_DISABLED:')\n",
    "            new_lines.append('    bar_mask = None')\n",
    "            changed = True\n",
    "    src = '\\n'.join(new_lines) + '\\n'\n",
    "\n",
    "if changed:\n",
    "    with open(script_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(src)\n",
    "    print('Patch uygulandı: --disable-barline-mask bayrağı ve mantığı eklendi')\n",
    "else:\n",
    "    print('Patch gerekmiyor: zaten uygulanmış görünüyor')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

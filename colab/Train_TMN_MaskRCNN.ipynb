{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab: Mount Google Drive\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping drive mount.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24e425",
   "metadata": {},
   "source": [
    "# TMN Mask R-CNN Training (Dedicated Notebook)\n",
    "This notebook focuses only on training to avoid mixing with augmentation tasks. It sets up GPU, loads DS2 Dense TMN from Drive, trains Mask R-CNN, and saves checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje Yapılandırması ve Kütüphanelerin İçe Aktarılması\n",
    "import os, sys, json, glob, time\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "print('GPU:', torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c52ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre Organizasyonu: Etiketler ve Bölümler\n",
    "# Tags: preprocess, train, eval, logs\n",
    "print('Tags: preprocess/train/eval/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametreleştirme: Config Sözlüğü ve Dataclass\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Artık DS2 Dense (SRC_ROOT) değil, TMN çıktılarından eğiteceğiz\n",
    "    OUT_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn'\n",
    "    IMG_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn/images'\n",
    "    BATCH_SIZE: int = 8\n",
    "    EPOCHS: int = 3\n",
    "    LR: float = 0.005\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 0.0005\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04363aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Günlükleme (Logging)\n",
    "import logging, os\n",
    "LOG_DIR = os.path.join(cfg.OUT_ROOT, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, handlers=[\n",
    "    logging.FileHandler(os.path.join(LOG_DIR, 'train.log')),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logging.info('Logging initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri İşleme Akışı ve Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS2TMNDataset(Dataset):\n",
    "    def __init__(self, images_dir, json_paths, transform=None):\n",
    "        import json\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.ann_by_img = {}\n",
    "        for jp in json_paths:\n",
    "            with open(jp,'r',encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            imgs = data.get('images') or []\n",
    "            anns = data.get('annotations') or {}\n",
    "            if isinstance(imgs, dict):\n",
    "                imgs = list(imgs.values())\n",
    "            for im in imgs:\n",
    "                fn = im.get('filename') or im.get('file_name')\n",
    "                if not fn:\n",
    "                    continue\n",
    "                self.images.append({'id': int(im.get('id')), 'filename': fn})\n",
    "            for k,v in anns.items():\n",
    "                img_id = int(v.get('img_id'))\n",
    "                self.ann_by_img.setdefault(img_id, []).append(v)\n",
    "        seen = set(); uniq=[]\n",
    "        for im in self.images:\n",
    "            if im['filename'] in seen: continue\n",
    "            seen.add(im['filename']); uniq.append(im)\n",
    "        self.images = uniq\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im = self.images[idx]\n",
    "        fn = im['filename']\n",
    "        path = os.path.join(cfg.IMG_ROOT, fn)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        anns = self.ann_by_img.get(im['id'], [])\n",
    "        boxes=[]; labels=[]\n",
    "        for a in anns:\n",
    "            b = a.get('a_bbox') or a.get('bbox')\n",
    "            cats = a.get('cat_id') or []\n",
    "            if b and len(b)>=4:\n",
    "                boxes.append([b[0], b[1], b[2], b[3]])\n",
    "                lab = int(cats[0]) if (isinstance(cats, list) and cats) else 0\n",
    "                labels.append(lab)\n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'image_id': torch.tensor([im['id']])\n",
    "        }\n",
    "        img = self.transform(img) if self.transform else self.to_tensor(img)\n",
    "        return img, target\n",
    "\n",
    "train_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "train_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=train_jsons)\n",
    "test_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=test_jsons)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "bs = cfg.BATCH_SIZE\n",
    "if torch.cuda.is_available():\n",
    "    name = torch.cuda.get_device_name(0).lower()\n",
    "    if 'a100' in name or 'l4' in name or 'v100' in name:\n",
    "        bs = max(bs, 8)\n",
    "    elif 't4' in name or 'p100' in name:\n",
    "        bs = min(bs, 4)\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
    "print({'batch_size': bs, 'train_len': len(train_ds), 'test_len': len(test_ds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d317b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modülerleştirme ve Model Kurulumu\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "num_classes = 1 + 8  # background + 8 TMN\n",
    "model = maskrcnn_resnet50_fpn(weights=None)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print('Model on', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Döngüsü (AMP) ve Checkpoint\n",
    "from torch.optim import SGD\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os, time\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=cfg.LR, momentum=cfg.MOMENTUM, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "CKPT_DIR = os.path.join(cfg.OUT_ROOT, 'checkpoints')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    t0 = time.time(); total = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total += losses.item()\n",
    "    dur = time.time()-t0\n",
    "    avg = total / max(1,len(train_loader))\n",
    "    logging.info({'epoch': epoch+1, 'loss': round(avg,3), 'sec': round(dur,1)})\n",
    "    ckpt = os.path.join(CKPT_DIR, f'maskrcnn_epoch{epoch+1}.pt')\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+1}, ckpt)\n",
    "    logging.info({'saved': ckpt})\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değerlendirme ve Görselleştirme\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def eval_show(n=3, thr=0.5):\n",
    "    shown = 0\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "        for img, out in zip(images, outputs):\n",
    "            if shown>=n: return\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "            ax.imshow(img.permute(1,2,0).cpu().numpy())\n",
    "            boxes = out['boxes'].cpu().numpy(); scores = out['scores'].cpu().numpy()\n",
    "            for b,s in zip(boxes, scores):\n",
    "                if s<thr: continue\n",
    "                x1,y1,x2,y2 = b\n",
    "                ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, color='y', linewidth=2))\n",
    "            ax.set_title(f'detections >= {thr}')\n",
    "            plt.show(); shown += 1\n",
    "\n",
    "eval_show(3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO mAP Evaluation on test shard\n",
    "import json, os\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Pick test JSON (first shard)\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "assert len(test_jsons)>0, 'No test JSONs found under OUT_ROOT/jsonlar'\n",
    "test_json = test_jsons[0]\n",
    "cocoGt = COCO(test_json)\n",
    "\n",
    "# Run model to collect detections in COCO format\n",
    "dets = []\n",
    "model.eval()\n",
    "import numpy as np\n",
    "@torch.no_grad()\n",
    "def collect_detections(max_images=500):\n",
    "    processed = 0\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "        for out, tgt in zip(outputs, targets):\n",
    "            img_id = int(tgt['image_id'].item())\n",
    "            boxes = out['boxes'].cpu().numpy()\n",
    "            scores = out['scores'].cpu().numpy()\n",
    "            labels = out['labels'].cpu().numpy()\n",
    "            for b, s, lab in zip(boxes, scores, labels):\n",
    "                if s < 0.05:\n",
    "                    continue\n",
    "                x1,y1,x2,y2 = b\n",
    "                dets.append({\n",
    "                    'image_id': img_id,\n",
    "                    'category_id': int(lab),\n",
    "                    'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n",
    "                    'score': float(s)\n",
    "                })\n",
    "        processed += len(images)\n",
    "        if processed >= max_images:\n",
    "            break\n",
    "collect_detections(max_images=2000)\n",
    "print('Detections:', len(dets))\n",
    "\n",
    "# Evaluate mAP\n",
    "if len(dets)==0:\n",
    "    print('No detections to evaluate.')\n",
    "else:\n",
    "    cocoDt = cocoGt.loadRes(dets)\n",
    "    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    # Save metrics\n",
    "    metrics = {\n",
    "        'AP@[.5:.95]': float(cocoEval.stats[0]),\n",
    "        'AP@0.5': float(cocoEval.stats[1]),\n",
    "        'AP@0.75': float(cocoEval.stats[2])\n",
    "    }\n",
    "    REPORT_DIR = os.path.join(cfg.OUT_ROOT, 'reports')\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "    with open(os.path.join(REPORT_DIR, 'metrics.json'), 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print('Saved metrics to', os.path.join(REPORT_DIR, 'metrics.json'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

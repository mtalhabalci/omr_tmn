{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab: Mount Google Drive\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping drive mount.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24e425",
   "metadata": {},
   "source": [
    "# TMN Mask R-CNN Training (Dedicated Notebook)\n",
    "This notebook focuses only on training to avoid mixing with augmentation tasks. It sets up GPU, loads DS2 Dense TMN from Drive, trains Mask R-CNN, and saves checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje Yapılandırması ve Kütüphanelerin İçe Aktarılması\n",
    "import os, sys, json, glob, time\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "print('GPU:', torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c52ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bölümler\n",
    "\n",
    "Bu defter şu bölümlerden oluşur:\n",
    "- preprocess: veri yolları ve dataloader hazırlığı\n",
    "- train: model kurulumu ve eğitim\n",
    "- eval: görselleştirme ve mAP değerlendirme\n",
    "- logs: eğitim günlükleri ve checkpoint konumu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametreleştirme: Config Sözlüğü ve Dataclass\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Eğitim girdileri: TMN dataset\n",
    "    OUT_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn'\n",
    "    IMG_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn/images'\n",
    "    # Eğitim çıktıları: ayrı bir train klasöründe kalıcı\n",
    "    TRAIN_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/train/ds2_dense_tmn'\n",
    "    # Model özel alt klasörü\n",
    "    MASKRCNN_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/train/ds2_dense_tmn/maskrcnn'\n",
    "    # Bellek için daha konservatif başlangıç batch boyutu\n",
    "    BATCH_SIZE: int = 2\n",
    "    EPOCHS: int = 3\n",
    "    LR: float = 0.005\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 0.0005\n",
    "    # Bellek kontrolleri\n",
    "    MAX_INSTANCES: Optional[int] = None   # Görsel başına sınır yok (RAM yeterliyse)\n",
    "    DATA_LOADER_PIN_MEMORY: bool = False  # RAM tüketimini azaltmak için kapalı\n",
    "    # Değerlendirme ayarları\n",
    "    EVAL_SPLIT: str = 'test'   # 'test' yoksa 'train' olarak ayarla\n",
    "    EVAL_SCORE_THR: float = 0.05\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)\n",
    "\n",
    "# Çalışma klasörü: tarih/saat etiketli alt klasör (maskrcnn altında)\n",
    "import time, os\n",
    "os.makedirs(cfg.MASKRCNN_ROOT, exist_ok=True)\n",
    "RUN_DIR = os.path.join(cfg.MASKRCNN_ROOT, time.strftime('%Y%m%d_%H%M'))\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print('RUN_DIR:', RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04363aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Günlükleme (Logging)\n",
    "import logging, os\n",
    "LOG_DIR = os.path.join(RUN_DIR, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, handlers=[\n",
    "    logging.FileHandler(os.path.join(LOG_DIR, 'train.log')),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logging.info('Logging initialized at %s', LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri İşleme Akışı ve Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS2TMNDataset(Dataset):\n",
    "    def __init__(self, images_dir, json_paths, transform=None, max_instances=None):\n",
    "        import json\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.max_instances = max_instances\n",
    "        self.items = []  # {'filename': str, 'image_id': int}\n",
    "        self.anns_by_fn = {}  # filename -> List[[x1,y1,x2,y2,label]]\n",
    "\n",
    "        seen_fn = set()\n",
    "        for jp in json_paths:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            imgs = data.get('images') or []\n",
    "            if isinstance(imgs, dict):\n",
    "                imgs = list(imgs.values())\n",
    "            id_to_fn = {}\n",
    "            for im in imgs:\n",
    "                fn = im.get('filename') or im.get('file_name')\n",
    "                if not fn:\n",
    "                    continue\n",
    "                try:\n",
    "                    iid = int(im.get('id')) if im.get('id') is not None else None\n",
    "                except Exception:\n",
    "                    iid = None\n",
    "                if iid is not None:\n",
    "                    id_to_fn[iid] = fn\n",
    "\n",
    "            anns = data.get('annotations') or {}\n",
    "            if isinstance(anns, dict):\n",
    "                ann_iter = anns.values()\n",
    "            else:\n",
    "                ann_iter = anns\n",
    "            for a in ann_iter:\n",
    "                img_id = a.get('img_id') or a.get('image_id')\n",
    "                if img_id is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    fn = id_to_fn[int(img_id)]\n",
    "                except Exception:\n",
    "                    continue\n",
    "                b = a.get('a_bbox') or a.get('bbox')\n",
    "                cats = a.get('cat_id') or a.get('category_id') or []\n",
    "                if not b or len(b) < 4:\n",
    "                    continue\n",
    "                # Etiket çözümleme (liste/tekil)\n",
    "                if isinstance(cats, list) and len(cats) > 0:\n",
    "                    lab = int(cats[0])\n",
    "                elif isinstance(cats, (int, str)):\n",
    "                    lab = int(cats)\n",
    "                else:\n",
    "                    lab = 0\n",
    "                self.anns_by_fn.setdefault(fn, []).append([\n",
    "                    float(b[0]), float(b[1]), float(b[2]), float(b[3]), lab\n",
    "                ])\n",
    "\n",
    "            # Bu shard'daki görselleri ekle (fn bazlı tekil)\n",
    "            for iid, fn in id_to_fn.items():\n",
    "                if fn in seen_fn:\n",
    "                    continue\n",
    "                seen_fn.add(fn)\n",
    "                # image_id'i bu shard'dan alıyoruz; test/train ayrıldığı için mAP eşleşmesi korunur\n",
    "                self.items.append({'filename': fn, 'image_id': int(iid) if iid is not None else -1})\n",
    "\n",
    "        # Görselleri alfabetik sırala (tekrar üretilebilirlik için)\n",
    "        self.items.sort(key=lambda x: x['filename'])\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im = self.items[idx]\n",
    "        fn = im['filename']\n",
    "        img_id = int(im['image_id'])\n",
    "        path = os.path.join(self.images_dir, fn)\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception:\n",
    "            W = H = 1\n",
    "            img = Image.new('RGB', (W, H), (0, 0, 0))\n",
    "            lst = []\n",
    "        else:\n",
    "            W, H = img.size\n",
    "            lst = self.anns_by_fn.get(fn, [])\n",
    "\n",
    "        boxes_labels = []\n",
    "        for rec in lst:\n",
    "            x1, y1, x2, y2, lab = rec\n",
    "            x1 = max(0, min(x1, W - 1)); y1 = max(0, min(y1, H - 1))\n",
    "            x2 = max(0, min(x2, W));     y2 = max(0, min(y2, H))\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                boxes_labels.append((x1, y1, x2, y2, lab))\n",
    "\n",
    "        # Instance sınırı (bellek için)\n",
    "        if self.max_instances and len(boxes_labels) > self.max_instances:\n",
    "            boxes_labels = boxes_labels[: self.max_instances]\n",
    "\n",
    "        boxes = [[x1, y1, x2, y2] for x1, y1, x2, y2, _ in boxes_labels]\n",
    "        labels = [lab for *_, lab in boxes_labels]\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            masks = torch.zeros((len(boxes), H, W), dtype=torch.bool)\n",
    "            for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "                masks[i, int(y1):int(y2), int(x1):int(x2)] = True\n",
    "        else:\n",
    "            masks = torch.zeros((0, H, W), dtype=torch.bool)\n",
    "\n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'masks': masks,\n",
    "            'image_id': torch.tensor([img_id], dtype=torch.int64)\n",
    "        }\n",
    "        img = self.transform(img) if self.transform else self.to_tensor(img)\n",
    "        return img, target\n",
    "\n",
    "train_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "train_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=train_jsons, max_instances=cfg.MAX_INSTANCES)\n",
    "test_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=test_jsons, max_instances=cfg.MAX_INSTANCES)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# RAM tüketimini kontrol altında tutmak için otomatik büyütmeyi kaldırdık\n",
    "bs = cfg.BATCH_SIZE\n",
    "# Colab'de worker öldürme sorunlarını önlemek için num_workers=0; pin_memory bellek için kapalı\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=0, pin_memory=cfg.DATA_LOADER_PIN_MEMORY, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=0, pin_memory=cfg.DATA_LOADER_PIN_MEMORY, collate_fn=collate_fn)\n",
    "print({'batch_size': bs, 'train_len': len(train_ds), 'test_len': len(test_ds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d317b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modülerleştirme ve Model Kurulumu\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "num_classes = 1 + 8  # background + 8 TMN\n",
    "model = maskrcnn_resnet50_fpn(weights=None)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print('Model on', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Döngüsü (AMP) ve Checkpoint\n",
    "from torch.optim import SGD\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os, time, gc\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=cfg.LR, momentum=cfg.MOMENTUM, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scaler = GradScaler('cuda', enabled=torch.cuda.is_available())\n",
    "CKPT_DIR = os.path.join(RUN_DIR, 'checkpoints')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    t0 = time.time(); total = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k,v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total += losses.item()\n",
    "        # Batch sonu temizlik (özellikle RAM/VRAM baskısını azaltmak için)\n",
    "        del images, targets, loss_dict, losses\n",
    "    dur = time.time()-t0\n",
    "    avg = total / max(1,len(train_loader))\n",
    "    logging.info({'epoch': epoch+1, 'loss': round(avg,3), 'sec': round(dur,1)})\n",
    "    ckpt = os.path.join(CKPT_DIR, f'maskrcnn_epoch{epoch+1}.pt')\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+1}, ckpt)\n",
    "    logging.info({'saved': ckpt})\n",
    "    # Epoch sonu bellek temizliği\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değerlendirme ve Görselleştirme\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def eval_show(n=3, thr=0.5):\n",
    "    shown = 0\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "        for img, out in zip(images, outputs):\n",
    "            if shown>=n: return\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "            ax.imshow(img.permute(1,2,0).cpu().numpy())\n",
    "            boxes = out['boxes'].cpu().numpy(); scores = out['scores'].cpu().numpy()\n",
    "            for b,s in zip(boxes, scores):\n",
    "                if s<thr: continue\n",
    "                x1,y1,x2,y2 = b\n",
    "                ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, color='y', linewidth=2))\n",
    "            ax.set_title(f'detections >= {thr}')\n",
    "            plt.show(); plt.close(fig)  # Bellek sızıntılarını önlemek için figürü kapat\n",
    "            shown += 1\n",
    "\n",
    "eval_show(3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO mAP Evaluation (train/test sabit eşleme, RAM dostu akış)\n",
    "import json, os, gc\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Split seçimi: 'train' -> train_jsons & train_loader, 'test' -> test_jsons & test_loader\n",
    "split = (cfg.EVAL_SPLIT or 'test').lower()\n",
    "if split == 'test':\n",
    "    assert len(test_jsons) > 0, \"test split için JSON bulunamadı (ör. deepscores_test.json)\"\n",
    "    EVAL_JSON = test_jsons[0]\n",
    "    eval_loader = test_loader\n",
    "elif split == 'train':\n",
    "    assert len(train_jsons) > 0, \"train split için JSON bulunamadı (ör. deepscores_train.json)\"\n",
    "    EVAL_JSON = train_jsons[0]\n",
    "    eval_loader = train_loader\n",
    "else:\n",
    "    raise ValueError(f\"Bilinmeyen EVAL_SPLIT: {split}. 'train' veya 'test' olmalı.\")\n",
    "\n",
    "print({'eval_split': split, 'json': EVAL_JSON})\n",
    "cocoGt = COCO(EVAL_JSON)\n",
    "\n",
    "# Akış tabanlı tespit toplama: JSONL dosyasına yaz, bellekte tutma\n",
    "REPORT_DIR = os.path.join(RUN_DIR, 'reports')\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "DETS_JSONL = os.path.join(REPORT_DIR, f'detections_{split}.jsonl')\n",
    "DETS_JSON = os.path.join(REPORT_DIR, f'detections_{split}.json')  # COCO loadRes JSON array ister\n",
    "\n",
    "model.eval()\n",
    "import numpy as np\n",
    "@torch.no_grad()\n",
    "def collect_detections_stream(score_thr=0.05):\n",
    "    # Var olan dosyayı temizle\n",
    "    if os.path.exists(DETS_JSONL):\n",
    "        os.remove(DETS_JSONL)\n",
    "    processed = 0\n",
    "    with open(DETS_JSONL, 'w', encoding='utf-8') as fw:\n",
    "        for images, targets in eval_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            for out, tgt in zip(outputs, targets):\n",
    "                img_id = int(tgt['image_id'].item())\n",
    "                boxes = out['boxes'].detach().cpu().numpy()\n",
    "                scores = out['scores'].detach().cpu().numpy()\n",
    "                labels = out['labels'].detach().cpu().numpy()\n",
    "                for b, s, lab in zip(boxes, scores, labels):\n",
    "                    if s < score_thr:\n",
    "                        continue\n",
    "                    x1,y1,x2,y2 = b\n",
    "                    rec = {\n",
    "                        'image_id': img_id,\n",
    "                        'category_id': int(lab),\n",
    "                        'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n",
    "                        'score': float(s)\n",
    "                    }\n",
    "                    fw.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "            # Bellek temizliği (batch bazlı)\n",
    "            del images, outputs\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            processed += len(targets)\n",
    "    return processed\n",
    "\n",
    "# Tüm seçilen split'i işle (RAM şişmeden)\n",
    "processed = collect_detections_stream(score_thr=cfg.EVAL_SCORE_THR)\n",
    "print(f'Processed images ({split}):', processed)\n",
    "\n",
    "# JSONL -> JSON Array (stream ederek)\n",
    "with open(DETS_JSONL, 'r', encoding='utf-8') as fr, open(DETS_JSON, 'w', encoding='utf-8') as fw:\n",
    "    fw.write('[')\n",
    "    first = True\n",
    "    for line in fr:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if not first:\n",
    "            fw.write(',')\n",
    "        fw.write(line)\n",
    "        first = False\n",
    "    fw.write(']')\n",
    "\n",
    "# Evaluate mAP\n",
    "# COCO loadRes dosya yolunu kabul eder (JSON array formatında)\n",
    "try:\n",
    "    cocoDt = cocoGt.loadRes(DETS_JSON)\n",
    "except Exception as e:\n",
    "    print('Failed to load detections for COCOeval:', e)\n",
    "    cocoDt = None\n",
    "\n",
    "if cocoDt is None:\n",
    "    print('No detections to evaluate or load failed.')\n",
    "else:\n",
    "    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    # Save metrics\n",
    "    metrics = {\n",
    "        'AP@[.5:.95]': float(cocoEval.stats[0]),\n",
    "        'AP@0.5': float(cocoEval.stats[1]),\n",
    "        'AP@0.75': float(cocoEval.stats[2])\n",
    "    }\n",
    "    with open(os.path.join(REPORT_DIR, f'metrics_{split}.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print('Saved metrics to', os.path.join(REPORT_DIR, f'metrics_{split}.json'))\n",
    "    # Bellek temizliği\n",
    "    del cocoDt, cocoEval\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458f3fb9",
   "metadata": {},
   "source": [
    "# Çalıştırma Sırası (Colab Run Order)\n",
    "\n",
    "Aşağıdaki akışı izleyin. Model hücreleri artık Dataset/DataLoader hücresinden hemen sonra yer alıyor.\n",
    "\n",
    "1) Drive mount (Colab)\n",
    "2) Bağımlılıklar (pycocotools, matplotlib)\n",
    "3) Config ve RUN_DIR oluşturma\n",
    "4) Kategori haritaları (CAT_MAP/INV_CAT_MAP/NUM_CLASSES)\n",
    "5) Dataset & DataLoader, label aralığı kontrolü\n",
    "6) Model seçimi (Dataset’ten hemen sonra):\n",
    "   - Önerilen: MobileNetV3-FPN (version fallback) hücresi\n",
    "   - Alternatif: ResNet50-FPN (ağır)\n",
    "   - Not: MobileNetV3-FPN (factory) sürümünüzde bulunmayabilir\n",
    "7) Memory-safe overrides (min/max size, RPN/ROI ayarları)\n",
    "8) Standart AMP eğitim döngüsü ve checkpoint\n",
    "9) Gradient accumulation örneği (OOM varsa; ana döngüye entegre edilebilir)\n",
    "10) Hızlı görselleştirme (opsiyonel)\n",
    "11) COCO mAP değerlendirme (EVAL_SPLIT: 'test'/'train')\n",
    "12) Çıktı özeti (RUN_DIR, checkpoints, raporlar)\n",
    "13) Dataset probe (opsiyonel)\n",
    "14) Drive'dan categories.json kopyala (opsiyonel ama tavsiye)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b44d91",
   "metadata": {},
   "source": [
    "# Hızlı Başlangıç\n",
    "\n",
    "Bu defteri Colab'da güvenle çalıştırmak için özet adımlar:\n",
    "\n",
    "- GPU: Runtime → Change runtime type → GPU seçin.\n",
    "- Sıra: 1) Drive mount, 2) Kütüphaneler, 3) Config, 4) Dataset/DataLoader, 5) Model, 6) Train, 7) Eval, 8) (Opsiyonel) Görselleştirme.\n",
    "- Config (Cell 5):\n",
    "  - `OUT_ROOT`/`IMG_ROOT`: TMN çıktıları (ds2_dense_tmn) klasörlerinize işaret etmeli.\n",
    "  - `BATCH_SIZE`: Küçük başlayın (2), A100’de stabil ise artırın.\n",
    "  - `EVAL_SPLIT`: 'train' veya 'test' (mAP raporu bu split’e göre yazılır).\n",
    "  - `MAX_INSTANCES`: `None` = sınırsız; RAM kısıtlıysa makul bir sayı verin.\n",
    "  - `DATA_LOADER_PIN_MEMORY`: Colab RAM baskısını azaltmak için varsayılan False.\n",
    "- Çıktılar: `RUN_DIR` otomatik oluşturulur (`maskrcnn/YYYYMMDD_HHMM`).\n",
    "  - `logs/` (eğitim günlüğü), `checkpoints/` (ağırlıklar), `reports/` (mAP ve tespitler) burada.\n",
    "- Değerlendirme: `EVAL_SPLIT`’e göre mAP yazılır: `reports/metrics_<split>.json`.\n",
    "- İpuçları: `num_workers=0`, `pin_memory=False` Colab stabilitesine yardımcı olur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b481e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab: Mount Google Drive\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Not in Colab; skipping drive mount.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab: Bağımlılıkları yükle (gerekliyse)\n",
    "import importlib, sys, subprocess\n",
    "\n",
    "def ensure(pkg, import_name=None, spec=None):\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "        print(f\"ok: {name}\")\n",
    "    except Exception:\n",
    "        cmd = [sys.executable, '-m', 'pip', 'install']\n",
    "        if spec:\n",
    "            cmd.append(spec)\n",
    "        else:\n",
    "            cmd.append(pkg)\n",
    "        print('installing:', ' '.join(cmd))\n",
    "        subprocess.check_call(cmd)\n",
    "        importlib.invalidate_caches()\n",
    "        importlib.import_module(name)\n",
    "        print(f\"installed: {name}\")\n",
    "\n",
    "# COCO eval için\n",
    "ensure('pycocotools', 'pycocotools')\n",
    "# Görselleştirme\n",
    "ensure('matplotlib', 'matplotlib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24e425",
   "metadata": {},
   "source": [
    "# TMN Mask R-CNN Training (Dedicated Notebook)\n",
    "This notebook focuses only on training to avoid mixing with augmentation tasks. It sets up GPU, loads DS2 Dense TMN from Drive, trains Mask R-CNN, and saves checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje Yapılandırması ve Kütüphanelerin İçe Aktarılması\n",
    "import os, sys, json, glob, time\n",
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "print('GPU:', torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametreleştirme: Config Sözlüğü ve Dataclass\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Eğitim girdileri: TMN dataset\n",
    "    OUT_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn'\n",
    "    IMG_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/ds2_dense_tmn/images'\n",
    "    # Eğitim çıktıları: ayrı bir train klasöründe kalıcı\n",
    "    TRAIN_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/train/ds2_dense_tmn'\n",
    "    # Model özel alt klasörü\n",
    "    MASKRCNN_ROOT: str = '/content/drive/MyDrive/omr_dataset/dataset/ds2/train/ds2_dense_tmn/maskrcnn'\n",
    "    # Bellek için daha konservatif başlangıç batch boyutu\n",
    "    BATCH_SIZE: int = 2\n",
    "    EPOCHS: int = 3\n",
    "    LR: float = 0.005\n",
    "    MOMENTUM: float = 0.9\n",
    "    WEIGHT_DECAY: float = 0.0005\n",
    "    # Bellek kontrolleri\n",
    "    MAX_INSTANCES: Optional[int] = None   # Görsel başına sınır yok (RAM yeterliyse)\n",
    "    DATA_LOADER_PIN_MEMORY: bool = False  # RAM tüketimini azaltmak için kapalı\n",
    "    # Değerlendirme ayarları\n",
    "    EVAL_SPLIT: str = 'test'   # 'test' yoksa 'train' olarak ayarla\n",
    "    EVAL_SCORE_THR: float = 0.05\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Yerel Windows ortamı: repo kökünde ds2_dense_tmn varsa yolları otomatik yerelle\n",
    "try:\n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    repo_root = Path(os.getcwd())\n",
    "    local_ds = repo_root / 'ds2_dense_tmn'\n",
    "    if not IN_COLAB and local_ds.exists():\n",
    "        cfg.OUT_ROOT = str(local_ds)\n",
    "        cfg.IMG_ROOT = str(local_ds / 'images')\n",
    "        cfg.TRAIN_ROOT = str(repo_root / 'train' / 'ds2_dense_tmn')\n",
    "        cfg.MASKRCNN_ROOT = str(repo_root / 'train' / 'ds2_dense_tmn' / 'maskrcnn')\n",
    "        print({'local_dataset_detected': True, 'OUT_ROOT': cfg.OUT_ROOT})\n",
    "except Exception as e:\n",
    "    print('Yerel yol ayarlama atlandı:', e)\n",
    "\n",
    "print(cfg)\n",
    "\n",
    "# Çalışma klasörü: tarih/saat etiketli alt klasör (maskrcnn altında)\n",
    "import time, os\n",
    "os.makedirs(cfg.MASKRCNN_ROOT, exist_ok=True)\n",
    "RUN_DIR = os.path.join(cfg.MASKRCNN_ROOT, time.strftime('%Y%m%d_%H%M'))\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print('RUN_DIR:', RUN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2011c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategori Haritası: category_id -> eğitim etiketi (1..K), 0 arkaplan\n",
    "import json, glob, os\n",
    "\n",
    "train_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "\n",
    "def build_category_maps(json_paths):\n",
    "    cats = set()\n",
    "    for jp in json_paths:\n",
    "        try:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            continue\n",
    "        anns = data.get('annotations') or {}\n",
    "        ann_iter = anns.values() if isinstance(anns, dict) else anns\n",
    "        for a in ann_iter:\n",
    "            cats_val = a.get('cat_id') or a.get('category_id')\n",
    "            if isinstance(cats_val, list):\n",
    "                for c in cats_val:\n",
    "                    try:\n",
    "                        cats.add(int(c))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            elif cats_val is not None:\n",
    "                try:\n",
    "                    cats.add(int(cats_val))\n",
    "                except Exception:\n",
    "                    pass\n",
    "    cats = sorted(cats)\n",
    "    cat_map = {orig: i+1 for i, orig in enumerate(cats)}  # 0: background\n",
    "    inv_cat_map = {v: k for k, v in cat_map.items()}\n",
    "    return cat_map, inv_cat_map\n",
    "\n",
    "ALL_JSONS = train_jsons + test_jsons\n",
    "CAT_MAP, INV_CAT_MAP = build_category_maps(ALL_JSONS)\n",
    "NUM_CLASSES = 1 + len(CAT_MAP)\n",
    "print({'num_classes': NUM_CLASSES, 'categories': len(CAT_MAP)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelişmiş Kategori Özeti: isim ve adetleri annotasyonlardan da topla\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# 1) categories alanından isimleri topla (varsa)\n",
    "def _collect_category_names_from_categories(json_paths):\n",
    "    names = {}\n",
    "    for jp in json_paths:\n",
    "        try:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            continue\n",
    "        cats = data.get('categories') or []\n",
    "        if isinstance(cats, dict):\n",
    "            cats = list(cats.values())\n",
    "        for c in cats:\n",
    "            try:\n",
    "                cid = int(c.get('id'))\n",
    "            except Exception:\n",
    "                continue\n",
    "            nm = c.get('name') or c.get('category_name') or None\n",
    "            if cid not in names and nm:\n",
    "                names[cid] = str(nm)\n",
    "    return names\n",
    "\n",
    "# 2) annotations içinden olası isim alanlarından topla ve adetleri say\n",
    "def _collect_from_annotations(json_paths):\n",
    "    counts = defaultdict(int)\n",
    "    ann_names = {}\n",
    "    candidate_keys = [\n",
    "        'category_name', 'cat_name', 'name', 'class_name', 'class',\n",
    "        'symbol', 'label', 'semantic', 'semantic_name', 'cat', 'category'\n",
    "    ]\n",
    "    for jp in json_paths:\n",
    "        try:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            continue\n",
    "        anns = data.get('annotations') or {}\n",
    "        ann_iter = anns.values() if isinstance(anns, dict) else anns\n",
    "        for a in ann_iter:\n",
    "            # id\n",
    "            cid_val = a.get('cat_id') or a.get('category_id')\n",
    "            try:\n",
    "                cid = int(cid_val)\n",
    "            except Exception:\n",
    "                continue\n",
    "            counts[cid] += 1\n",
    "            # isim ipuçları\n",
    "            for k in candidate_keys:\n",
    "                v = a.get(k)\n",
    "                if isinstance(v, str) and len(v) > 0:\n",
    "                    if cid not in ann_names:\n",
    "                        ann_names[cid] = v\n",
    "                    break\n",
    "    return counts, ann_names\n",
    "\n",
    "NAMES_FROM_CATS = _collect_category_names_from_categories(ALL_JSONS)\n",
    "COUNTS_BY_CAT, ANN_NAME_BY_CAT = _collect_from_annotations(ALL_JSONS)\n",
    "\n",
    "# Öncelik: categories -> annotation isimleri\n",
    "NAME_BY_CAT_ID = dict(NAMES_FROM_CATS)\n",
    "for cid, nm in ANN_NAME_BY_CAT.items():\n",
    "    NAME_BY_CAT_ID.setdefault(cid, nm)\n",
    "\n",
    "# 3) Referans isimler (understanding_dataset/categories.json) -> eksik isimler için yedek\n",
    "try:\n",
    "    ref_path = os.path.join(os.getcwd(), 'understanding_dataset', 'categories.json')\n",
    "    REF_NAME_BY_ID = {}\n",
    "    if os.path.exists(ref_path):\n",
    "        with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "            ref = json.load(f)\n",
    "        for k, v in ref.items():\n",
    "            try:\n",
    "                cid = int(k)\n",
    "            except Exception:\n",
    "                continue\n",
    "            nm = v.get('name')\n",
    "            if isinstance(nm, str) and nm:\n",
    "                REF_NAME_BY_ID[cid] = nm\n",
    "        # Eksik olanları referanstan tamamla (dataset/annotation isimleri öncelikli)\n",
    "        for cid, nm in REF_NAME_BY_ID.items():\n",
    "            NAME_BY_CAT_ID.setdefault(cid, nm)\n",
    "        print(f\"Referans isimler yüklendi: {len(REF_NAME_BY_ID)} id\")\n",
    "    else:\n",
    "        print('Referans isim dosyası yok: understanding_dataset/categories.json')\n",
    "except Exception as e:\n",
    "    print('Referans isimler okunamadı:', e)\n",
    "\n",
    "ORIG_CATEGORY_IDS = sorted(CAT_MAP.keys())\n",
    "TRAIN_LABEL_TO_CATEGORY = {tr: INV_CAT_MAP[tr] for tr in sorted(INV_CAT_MAP.keys())}\n",
    "\n",
    "print('Toplam kategori:', len(ORIG_CATEGORY_IDS))\n",
    "print('İsmi bilinen kategori sayısı:', sum(1 for cid in ORIG_CATEGORY_IDS if cid in NAME_BY_CAT_ID))\n",
    "\n",
    "# Listede çok kategori olabilir; çıktıyı sınırlamak için ayar\n",
    "max_rows = 120  # gerekirse artır/azalt\n",
    "printed = 0\n",
    "print('\\nEğitim label -> category_id | adet | isim')\n",
    "for tr in range(1, NUM_CLASSES):\n",
    "    cid = TRAIN_LABEL_TO_CATEGORY.get(tr)\n",
    "    cnt = int(COUNTS_BY_CAT.get(cid, 0))\n",
    "    nm = NAME_BY_CAT_ID.get(cid)\n",
    "    nm_disp = nm if nm is not None else '-'\n",
    "    print(f\"  {tr:3d} -> {cid:4d} | {cnt:6d} | {nm_disp}\")\n",
    "    printed += 1\n",
    "    if printed >= max_rows and NUM_CLASSES-1 > max_rows:\n",
    "        remaining = (NUM_CLASSES-1) - max_rows\n",
    "        print(f\"... {remaining} satır daha (max_rows={max_rows}). Değeri arttırabilirsiniz.\")\n",
    "        break\n",
    "\n",
    "# Dizi olarak saklama (tam liste)\n",
    "TRAIN_CATEGORY_IDS = [TRAIN_LABEL_TO_CATEGORY[i] for i in range(1, NUM_CLASSES)]\n",
    "TRAIN_CATEGORY_NAMES = [NAME_BY_CAT_ID.get(cid) for cid in TRAIN_CATEGORY_IDS]\n",
    "print('\\nTRAIN_CATEGORY_IDS (ilk 50):', TRAIN_CATEGORY_IDS[:50])\n",
    "print('TRAIN_CATEGORY_NAMES (ilk 50):', TRAIN_CATEGORY_NAMES[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategori özetini JSON olarak kaydet (RUN_DIR/reports/category_summary.json)\n",
    "import os, json\n",
    "\n",
    "if 'RUN_DIR' not in globals():\n",
    "    print('RUN_DIR tanımsız. Önce Config hücresini çalıştırın.')\n",
    "else:\n",
    "    REPORT_DIR = os.path.join(RUN_DIR, 'reports')\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "    out_path = os.path.join(REPORT_DIR, 'category_summary.json')\n",
    "\n",
    "    items = []\n",
    "    for tr in range(1, NUM_CLASSES):\n",
    "        cid = TRAIN_LABEL_TO_CATEGORY.get(tr)\n",
    "        cnt = int(COUNTS_BY_CAT.get(cid, 0))\n",
    "        nm = NAME_BY_CAT_ID.get(cid)\n",
    "        items.append({\n",
    "            'train_label': int(tr),\n",
    "            'category_id': int(cid) if cid is not None else None,\n",
    "            'count': cnt,\n",
    "            'name': nm\n",
    "        })\n",
    "\n",
    "    summary = {\n",
    "        'total_categories': int(len(ORIG_CATEGORY_IDS)),\n",
    "        'with_names': int(sum(1 for cid in ORIG_CATEGORY_IDS if cid in NAME_BY_CAT_ID)),\n",
    "        'train_labels': int(NUM_CLASSES - 1),\n",
    "        'category_ids': [int(x) for x in TRAIN_CATEGORY_IDS],\n",
    "        'category_names': TRAIN_CATEGORY_NAMES,\n",
    "        'items': items\n",
    "    }\n",
    "\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    print('Kategori özeti kaydedildi ->', out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategori Özeti: ID ve (varsa) isimleri yazdır\n",
    "import json\n",
    "\n",
    "def _collect_category_names(json_paths):\n",
    "    names = {}\n",
    "    for jp in json_paths:\n",
    "        try:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            continue\n",
    "        cats = data.get('categories') or []\n",
    "        if isinstance(cats, dict):\n",
    "            cats = list(cats.values())\n",
    "        for c in cats:\n",
    "            try:\n",
    "                cid = int(c.get('id'))\n",
    "            except Exception:\n",
    "                continue\n",
    "            nm = c.get('name') or c.get('category_name') or None\n",
    "            if cid not in names and nm:\n",
    "                names[cid] = str(nm)\n",
    "    return names\n",
    "\n",
    "NAME_BY_CAT_ID = _collect_category_names(ALL_JSONS)\n",
    "\n",
    "ORIG_CATEGORY_IDS = sorted(CAT_MAP.keys())\n",
    "TRAIN_LABEL_TO_CATEGORY = {tr: INV_CAT_MAP[tr] for tr in sorted(INV_CAT_MAP.keys())}\n",
    "\n",
    "print('Orijinal category_id listesi (sıralı):', ORIG_CATEGORY_IDS)\n",
    "print('Toplam kategori:', len(ORIG_CATEGORY_IDS))\n",
    "print('\\nEğitim label -> category_id (ve ad):')\n",
    "for tr in range(1, NUM_CLASSES):\n",
    "    cid = TRAIN_LABEL_TO_CATEGORY.get(tr)\n",
    "    nm = NAME_BY_CAT_ID.get(cid)\n",
    "    if nm is not None:\n",
    "        print(f'  {tr:2d} -> {cid}  ({nm})')\n",
    "    else:\n",
    "        print(f'  {tr:2d} -> {cid}')\n",
    "\n",
    "# Opsiyonel: dizi olarak sakla\n",
    "TRAIN_CATEGORY_IDS = [TRAIN_LABEL_TO_CATEGORY[i] for i in range(1, NUM_CLASSES)]\n",
    "TRAIN_CATEGORY_NAMES = [NAME_BY_CAT_ID.get(cid) for cid in TRAIN_CATEGORY_IDS]\n",
    "print('\\nTRAIN_CATEGORY_IDS:', TRAIN_CATEGORY_IDS)\n",
    "print('TRAIN_CATEGORY_NAMES:', TRAIN_CATEGORY_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04363aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Günlükleme (Logging)\n",
    "import logging, os\n",
    "LOG_DIR = os.path.join(RUN_DIR, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, handlers=[\n",
    "    logging.FileHandler(os.path.join(LOG_DIR, 'train.log')),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logging.info('Logging initialized at %s', LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri İşleme Akışı ve Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS2TMNDataset(Dataset):\n",
    "    def __init__(self, images_dir, json_paths, transform=None, max_instances=None, category_map=None):\n",
    "        import json\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.max_instances = max_instances\n",
    "        self.category_map = category_map\n",
    "        self.items = []  # {'filename': str, 'image_id': int}\n",
    "        self.anns_by_fn = {}  # filename -> List[[x1,y1,x2,y2,label]]\n",
    "\n",
    "        seen_fn = set()\n",
    "        for jp in json_paths:\n",
    "            with open(jp, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            imgs = data.get('images') or []\n",
    "            if isinstance(imgs, dict):\n",
    "                imgs = list(imgs.values())\n",
    "            id_to_fn = {}\n",
    "            for im in imgs:\n",
    "                fn = im.get('filename') or im.get('file_name')\n",
    "                if not fn:\n",
    "                    continue\n",
    "                try:\n",
    "                    iid = int(im.get('id')) if im.get('id') is not None else None\n",
    "                except Exception:\n",
    "                    iid = None\n",
    "                if iid is not None:\n",
    "                    id_to_fn[iid] = fn\n",
    "\n",
    "            anns = data.get('annotations') or {}\n",
    "            ann_iter = anns.values() if isinstance(anns, dict) else anns\n",
    "            for a in ann_iter:\n",
    "                img_id = a.get('img_id') or a.get('image_id')\n",
    "                if img_id is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    fn = id_to_fn[int(img_id)]\n",
    "                except Exception:\n",
    "                    continue\n",
    "                b = a.get('a_bbox') or a.get('bbox')\n",
    "                cats = a.get('cat_id') or a.get('category_id') or []\n",
    "                if not b or len(b) < 4:\n",
    "                    continue\n",
    "                # Etiket çözümleme (liste/tekil)\n",
    "                if isinstance(cats, list) and len(cats) > 0:\n",
    "                    orig_lab = int(cats[0])\n",
    "                elif isinstance(cats, (int, str)):\n",
    "                    orig_lab = int(cats)\n",
    "                else:\n",
    "                    orig_lab = 0\n",
    "                # Eğitim için map'lenmiş etiket (1..K), 0 arkaplan kullanılmaz\n",
    "                if self.category_map is not None:\n",
    "                    mapped = self.category_map.get(orig_lab)\n",
    "                    if mapped is None:\n",
    "                        # bilinmeyense atla\n",
    "                        continue\n",
    "                    lab_to_use = int(mapped)\n",
    "                else:\n",
    "                    lab_to_use = int(orig_lab)\n",
    "                self.anns_by_fn.setdefault(fn, []).append([\n",
    "                    float(b[0]), float(b[1]), float(b[2]), float(b[3]), lab_to_use\n",
    "])\n",
    "\n",
    "            # Bu shard'daki görselleri ekle (fn bazlı tekil)\n",
    "            for iid, fn in id_to_fn.items():\n",
    "                if fn in seen_fn:\n",
    "                    continue\n",
    "                seen_fn.add(fn)\n",
    "                # image_id'i bu shard'dan alıyoruz; test/train ayrıldığı için mAP eşleşmesi korunur\n",
    "                self.items.append({'filename': fn, 'image_id': int(iid) if iid is not None else -1})\n",
    "\n",
    "        # Görselleri alfabetik sırala (tekrar üretilebilirlik için)\n",
    "        self.items.sort(key=lambda x: x['filename'])\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im = self.items[idx]\n",
    "        fn = im['filename']\n",
    "        img_id = int(im['image_id'])\n",
    "        path = os.path.join(self.images_dir, fn)\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception:\n",
    "            W = H = 1\n",
    "            img = Image.new('RGB', (W, H), (0, 0, 0))\n",
    "            lst = []\n",
    "        else:\n",
    "            W, H = img.size\n",
    "            lst = self.anns_by_fn.get(fn, [])\n",
    "\n",
    "        boxes_labels = []\n",
    "        for rec in lst:\n",
    "            x1, y1, x2, y2, lab = rec\n",
    "            x1 = max(0, min(x1, W - 1)); y1 = max(0, min(y1, H - 1))\n",
    "            x2 = max(0, min(x2, W));     y2 = max(0, min(y2, H))\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                boxes_labels.append((x1, y1, x2, y2, lab))\n",
    "\n",
    "        # Instance sınırı (bellek için)\n",
    "        if self.max_instances and len(boxes_labels) > self.max_instances:\n",
    "            boxes_labels = boxes_labels[: self.max_instances]\n",
    "\n",
    "        boxes = [[x1, y1, x2, y2] for x1, y1, x2, y2, _ in boxes_labels]\n",
    "        labels = [lab for *_, lab in boxes_labels]\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            masks = torch.zeros((len(boxes), H, W), dtype=torch.bool)\n",
    "            for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "                masks[i, int(y1):int(y2), int(x1):int(x2)] = True\n",
    "        else:\n",
    "            masks = torch.zeros((0, H, W), dtype=torch.bool)\n",
    "\n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'masks': masks,\n",
    "            'image_id': torch.tensor([img_id], dtype=torch.int64)\n",
    "        }\n",
    "        img = self.transform(img) if self.transform else self.to_tensor(img)\n",
    "        return img, target\n",
    "\n",
    "train_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*train*.json\"))\n",
    "test_jsons = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*test*.json\"))\n",
    "train_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=train_jsons, max_instances=cfg.MAX_INSTANCES, category_map=CAT_MAP)\n",
    "test_ds = DS2TMNDataset(images_dir=cfg.IMG_ROOT, json_paths=test_jsons, max_instances=cfg.MAX_INSTANCES, category_map=CAT_MAP)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# RAM tüketimini kontrol altında tutmak için otomatik büyütmeyi kaldırdık\n",
    "bs = cfg.BATCH_SIZE\n",
    "# Colab'de worker öldürme sorunlarını önlemek için num_workers=0; pin_memory bellek için kapalı\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=0, pin_memory=cfg.DATA_LOADER_PIN_MEMORY, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=0, pin_memory=cfg.DATA_LOADER_PIN_MEMORY, collate_fn=collate_fn)\n",
    "print({'batch_size': bs, 'train_len': len(train_ds), 'test_len': len(test_ds)})\n",
    "\n",
    "# Etiket aralığı hızlı kontrol (örneklem)\n",
    "def _check_label_ranges(ds, name, max_samples=100):\n",
    "    seen_min, seen_max, checked, bad = None, None, 0, 0\n",
    "    for i in range(min(max_samples, len(ds))):\n",
    "        _, t = ds[i]\n",
    "        l = t['labels']\n",
    "        if l.numel() == 0:\n",
    "            continue\n",
    "        lmin = int(l.min())\n",
    "        lmax = int(l.max())\n",
    "        seen_min = lmin if seen_min is None else min(seen_min, lmin)\n",
    "        seen_max = lmax if seen_max is None else max(seen_max, lmax)\n",
    "        if (l < 1).any() or (l > (NUM_CLASSES-1)).any():\n",
    "            bad += 1\n",
    "        checked += 1\n",
    "    print({name: {'sample_min': seen_min, 'sample_max': seen_max, 'checked': checked, 'out_of_range_samples': bad}})\n",
    "\n",
    "_check_label_ranges(train_ds, 'train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lightweight Mask R-CNN (MobileNetV3-FPN) with version fallback (Önerilen)\n",
    "import os, torch, torchvision\n",
    "from typing import Optional\n",
    "\n",
    "# Ensure NUM_CLASSES is available (compute from CAT_MAP if possible)\n",
    "if 'NUM_CLASSES' not in globals():\n",
    "    if 'CAT_MAP' in globals():\n",
    "        NUM_CLASSES = 1 + len(CAT_MAP)\n",
    "        print({'computed_NUM_CLASSES': NUM_CLASSES})\n",
    "    else:\n",
    "        raise RuntimeError(\"NUM_CLASSES tanımlı değil. Lütfen önce 'Config' ve 'Kategori Haritası' hücrelerini çalıştırın.\")\n",
    "\n",
    "print({'torch': torch.__version__, 'torchvision': torchvision.__version__})\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model: Optional[torch.nn.Module] = None\n",
    "used_impl = None\n",
    "\n",
    "# Try factory API first; fallback to manual backbone build if unavailable\n",
    "try:\n",
    "    from torchvision.models.detection import maskrcnn_mobilenet_v3_large_fpn\n",
    "    model = maskrcnn_mobilenet_v3_large_fpn(num_classes=NUM_CLASSES)\n",
    "    used_impl = 'factory'\n",
    "except Exception as e:\n",
    "    print('maskrcnn_mobilenet_v3_large_fpn not available, falling back:', e)\n",
    "    from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
    "    from torchvision.models.detection import MaskRCNN\n",
    "    backbone = mobilenet_backbone('mobilenet_v3_large', pretrained=True, fpn=True, trainable_layers=3)\n",
    "    model = MaskRCNN(backbone, num_classes=NUM_CLASSES)\n",
    "    used_impl = 'backbone_utils'\n",
    "\n",
    "# Tight memory settings\n",
    "if hasattr(model, 'transform'):\n",
    "    if hasattr(model.transform, 'min_size'):\n",
    "        model.transform.min_size = [448]  # list required by torchvision\n",
    "    if hasattr(model.transform, 'max_size'):\n",
    "        model.transform.max_size = 768\n",
    "if hasattr(model, 'roi_heads'):\n",
    "    if hasattr(model.roi_heads, 'detections_per_img'):\n",
    "        model.roi_heads.detections_per_img = 25\n",
    "    if hasattr(model.roi_heads, 'box_batch_size_per_image'):\n",
    "        model.roi_heads.box_batch_size_per_image = 128\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Anchor generator guard to match backbone feature maps\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "def _configure_anchor_generator(model, device, im_size=256):\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 3, im_size, im_size, device=device)\n",
    "            feats = model.backbone(x)\n",
    "        if isinstance(feats, dict):\n",
    "            n = len(feats)\n",
    "        elif isinstance(feats, (list, tuple)):\n",
    "            n = len(feats)\n",
    "        else:\n",
    "            n = 1\n",
    "        base_sizes = (32, 64, 128, 256, 512, 1024)\n",
    "        sizes = tuple((base_sizes[i],) for i in range(n))\n",
    "        ratios = tuple(((0.5, 1.0, 2.0),) for _ in range(n))\n",
    "        model.rpn.anchor_generator = AnchorGenerator(sizes=sizes, aspect_ratios=ratios)\n",
    "        print(f'AnchorGenerator configured: levels={n}, sizes={[list(s) for s in sizes]}')\n",
    "    except Exception as e:\n",
    "        print('Anchor guard skipped:', e)\n",
    "    finally:\n",
    "        try:\n",
    "            del x, feats\n",
    "        except Exception:\n",
    "            pass\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "_configure_anchor_generator(model, device)\n",
    "\n",
    "print(f'Mask R-CNN (MobileNetV3-FPN via {used_impl}) ready:', 'CUDA' if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d317b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modülerleştirme ve Model Kurulumu\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "num_classes = NUM_CLASSES  # background(0) + K kategori (1..K)\n",
    "model = maskrcnn_resnet50_fpn(weights=None)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print('Model on', device, '| num_classes =', num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lightweight Mask R-CNN (MobilenetV3-FPN) with tight memory settings (factory with fallback)\n",
    "import torch, os, torchvision\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from typing import Optional\n",
    "\n",
    "# Ensure NUM_CLASSES exists\n",
    "if 'NUM_CLASSES' not in globals():\n",
    "    if 'CAT_MAP' in globals():\n",
    "        NUM_CLASSES = 1 + len(CAT_MAP)\n",
    "        print({'computed_NUM_CLASSES': NUM_CLASSES})\n",
    "    else:\n",
    "        raise RuntimeError(\"NUM_CLASSES tanımlı değil. Lütfen önce 'Config' ve 'Kategori Haritası' hücrelerini çalıştırın.\")\n",
    "\n",
    "print({'torch': torch.__version__, 'torchvision': torchvision.__version__})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model: Optional[torch.nn.Module] = None\n",
    "used_impl = None\n",
    "\n",
    "# Try factory import; fallback to backbone_utils + MaskRCNN if unavailable\n",
    "try:\n",
    "    from torchvision.models.detection import maskrcnn_mobilenet_v3_large_fpn\n",
    "    model = maskrcnn_mobilenet_v3_large_fpn(num_classes=NUM_CLASSES)\n",
    "    used_impl = 'factory'\n",
    "except Exception as e:\n",
    "    print('maskrcnn_mobilenet_v3_large_fpn not available, falling back:', e)\n",
    "    from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
    "    from torchvision.models.detection import MaskRCNN\n",
    "    backbone = mobilenet_backbone('mobilenet_v3_large', pretrained=True, fpn=True, trainable_layers=3)\n",
    "    model = MaskRCNN(backbone, num_classes=NUM_CLASSES)\n",
    "    used_impl = 'backbone_utils'\n",
    "\n",
    "# shrink image sizes\n",
    "if hasattr(model, 'transform'):\n",
    "    if hasattr(model.transform, 'min_size'):\n",
    "        model.transform.min_size = [448]  # list required by torchvision transform\n",
    "    if hasattr(model.transform, 'max_size'):\n",
    "        model.transform.max_size = 768\n",
    "# tighten ROI\n",
    "if hasattr(model, 'roi_heads'):\n",
    "    if hasattr(model.roi_heads, 'detections_per_img'):\n",
    "        model.roi_heads.detections_per_img = 25\n",
    "    if hasattr(model.roi_heads, 'box_batch_size_per_image'):\n",
    "        model.roi_heads.box_batch_size_per_image = 128\n",
    "model.to(device)\n",
    "\n",
    "# Ensure anchors match backbone feature maps and proper tuple-of-tuples shape\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "def _configure_anchor_generator(model, device, im_size=256):\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 3, im_size, im_size, device=device)\n",
    "            feats = model.backbone(x)\n",
    "        if isinstance(feats, dict):\n",
    "            n = len(feats)\n",
    "        elif isinstance(feats, (list, tuple)):\n",
    "            n = len(feats)\n",
    "        else:\n",
    "            n = 1\n",
    "        base_sizes = (32, 64, 128, 256, 512, 1024)\n",
    "        sizes = tuple((base_sizes[i],) for i in range(n))\n",
    "        ratios = tuple(((0.5, 1.0, 2.0),) for _ in range(n))\n",
    "        model.rpn.anchor_generator = AnchorGenerator(sizes=sizes, aspect_ratios=ratios)\n",
    "        print(f'AnchorGenerator configured: levels={n}, sizes={[list(s) for s in sizes]}')\n",
    "    except Exception as e:\n",
    "        print('Anchor guard skipped:', e)\n",
    "    finally:\n",
    "        try:\n",
    "            del x, feats\n",
    "        except Exception:\n",
    "            pass\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "_configure_anchor_generator(model, device)\n",
    "\n",
    "print('MobilenetV3-FPN Mask R-CNN ready via', used_impl, '|', 'CUDA' if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Döngüsü (AMP) ve Checkpoint\n",
    "from torch.optim import SGD\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os, time, gc\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=cfg.LR, momentum=cfg.MOMENTUM, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scaler = GradScaler('cuda', enabled=torch.cuda.is_available())\n",
    "CKPT_DIR = os.path.join(RUN_DIR, 'checkpoints')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    t0 = time.time(); total = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k,v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total += losses.item()\n",
    "        # Batch sonu temizlik (özellikle RAM/VRAM baskısını azaltmak için)\n",
    "        del images, targets, loss_dict, losses\n",
    "    dur = time.time()-t0\n",
    "    avg = total / max(1,len(train_loader))\n",
    "    logging.info({'epoch': epoch+1, 'loss': round(avg,3), 'sec': round(dur,1)})\n",
    "    ckpt = os.path.join(CKPT_DIR, f'maskrcnn_epoch{epoch+1}.pt')\n",
    "    torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+1}, ckpt)\n",
    "    logging.info({'saved': ckpt})\n",
    "    # Epoch sonu bellek temizliği\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değerlendirme ve Görselleştirme\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def eval_show(n=3, thr=0.5):\n",
    "    shown = 0\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "        for img, out in zip(images, outputs):\n",
    "            if shown>=n: return\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "            ax.imshow(img.permute(1,2,0).cpu().numpy())\n",
    "            boxes = out['boxes'].cpu().numpy(); scores = out['scores'].cpu().numpy()\n",
    "            for b,s in zip(boxes, scores):\n",
    "                if s<thr: continue\n",
    "                x1,y1,x2,y2 = b\n",
    "                ax.add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, color='y', linewidth=2))\n",
    "            ax.set_title(f'detections >= {thr}')\n",
    "            plt.show(); plt.close(fig)  # Bellek sızıntılarını önlemek için figürü kapat\n",
    "            shown += 1\n",
    "\n",
    "eval_show(3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO mAP Evaluation (train/test sabit eşleme, RAM dostu akış)\n",
    "import json, os, gc\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Split seçimi: 'train' -> train_jsons & train_loader, 'test' -> test_jsons & test_loader\n",
    "split = (cfg.EVAL_SPLIT or 'test').lower()\n",
    "if split == 'test':\n",
    "    assert len(test_jsons) > 0, \"test split için JSON bulunamadı (ör. deepscores_test.json)\"\n",
    "    EVAL_JSON = test_jsons[0]\n",
    "    eval_loader = test_loader\n",
    "elif split == 'train':\n",
    "    assert len(train_jsons) > 0, \"train split için JSON bulunamadı (ör. deepscores_train.json)\"\n",
    "    EVAL_JSON = train_jsons[0]\n",
    "    eval_loader = train_loader\n",
    "else:\n",
    "    raise ValueError(f\"Bilinmeyen EVAL_SPLIT: {split}. 'train' veya 'test' olmalı.\")\n",
    "\n",
    "print({'eval_split': split, 'json': EVAL_JSON})\n",
    "\n",
    "# Eğer GT JSON'da categories yoksa veya isimler boşsa -> geçici bir GT yaz ve onu kullan\n",
    "try:\n",
    "    with open(EVAL_JSON, 'r', encoding='utf-8') as f:\n",
    "        gt_data = json.load(f)\n",
    "except Exception as e:\n",
    "    gt_data = None\n",
    "    print('GT json okunamadı:', e)\n",
    "\n",
    "def _extract_unique_cat_ids(annotations):\n",
    "    ids = set()\n",
    "    if isinstance(annotations, dict):\n",
    "        ann_iter = annotations.values()\n",
    "    else:\n",
    "        ann_iter = annotations or []\n",
    "    for a in ann_iter:\n",
    "        if not isinstance(a, dict):\n",
    "            continue\n",
    "        cid_val = a.get('cat_id') or a.get('category_id')\n",
    "        if isinstance(cid_val, list) and cid_val:\n",
    "            try:\n",
    "                ids.add(int(cid_val[0]))\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                if cid_val is not None:\n",
    "                    ids.add(int(cid_val))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return sorted(ids)\n",
    "\n",
    "# Referans isimler (understanding_dataset/categories.json) -> opsiyonel\n",
    "REF_NAME_BY_ID = {}\n",
    "try:\n",
    "    ref_path = os.path.join(os.getcwd(), 'understanding_dataset', 'categories.json')\n",
    "    if os.path.exists(ref_path):\n",
    "        with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "            ref = json.load(f)\n",
    "        for k, v in ref.items():\n",
    "            try:\n",
    "                cid = int(k)\n",
    "            except Exception:\n",
    "                continue\n",
    "            nm = v.get('name')\n",
    "            if isinstance(nm, str) and nm:\n",
    "                REF_NAME_BY_ID[cid] = nm\n",
    "except Exception as e:\n",
    "    print('Referans isimler okunamadı:', e)\n",
    "\n",
    "USE_JSON = EVAL_JSON\n",
    "if gt_data is not None:\n",
    "    cats = gt_data.get('categories')\n",
    "    need_patch = False\n",
    "    if not cats:\n",
    "        need_patch = True\n",
    "    else:\n",
    "        # categories varsa ama isimleri eksikse yine patchle\n",
    "        def _has_name(c):\n",
    "            return isinstance(c, dict) and (c.get('name') or c.get('category_name'))\n",
    "        if isinstance(cats, dict):\n",
    "            cats_list = list(cats.values())\n",
    "        else:\n",
    "            cats_list = cats\n",
    "        if not all(_has_name(c) for c in cats_list):\n",
    "            need_patch = True\n",
    "    if need_patch:\n",
    "        cat_ids = _extract_unique_cat_ids(gt_data.get('annotations') or [])\n",
    "        patched_cats = []\n",
    "        for cid in cat_ids:\n",
    "            name = REF_NAME_BY_ID.get(cid, f'cat_{cid}')\n",
    "            patched_cats.append({'id': int(cid), 'name': name})\n",
    "        gt_data['categories'] = patched_cats\n",
    "        REPORT_DIR = os.path.join(RUN_DIR, 'reports')\n",
    "        os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "        patched_path = os.path.join(REPORT_DIR, f'gt_with_categories_{split}.json')\n",
    "        with open(patched_path, 'w', encoding='utf-8') as fw:\n",
    "            json.dump(gt_data, fw, ensure_ascii=False)\n",
    "        USE_JSON = patched_path\n",
    "        print({'gt_patched': True, 'path': patched_path, 'cat_count': len(patched_cats)})\n",
    "\n",
    "cocoGt = COCO(USE_JSON)\n",
    "\n",
    "# Akış tabanlı tespit toplama: JSONL dosyasına yaz, bellekte tutma\n",
    "REPORT_DIR = os.path.join(RUN_DIR, 'reports')\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "DETS_JSONL = os.path.join(REPORT_DIR, f'detections_{split}.jsonl')\n",
    "DETS_JSON = os.path.join(REPORT_DIR, f'detections_{split}.json')  # COCO loadRes JSON array ister\n",
    "\n",
    "model.eval()\n",
    "import numpy as np\n",
    "@torch.no_grad()\n",
    "def collect_detections_stream(score_thr=0.05):\n",
    "    # Var olan dosyayı temizle\n",
    "    if os.path.exists(DETS_JSONL):\n",
    "        os.remove(DETS_JSONL)\n",
    "    processed = 0\n",
    "    with open(DETS_JSONL, 'w', encoding='utf-8') as fw:\n",
    "        for images, targets in eval_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            for out, tgt in zip(outputs, targets):\n",
    "                img_id = int(tgt['image_id'].item())\n",
    "                boxes = out['boxes'].detach().cpu().numpy()\n",
    "                scores = out['scores'].detach().cpu().numpy()\n",
    "                labels = out['labels'].detach().cpu().numpy()\n",
    "                for b, s, lab in zip(boxes, scores, labels):\n",
    "                    if s < score_thr:\n",
    "                        continue\n",
    "                    x1,y1,x2,y2 = b\n",
    "                    # Eğitim label'ını COCO GT'deki orijinal category_id'ye geri çevir\n",
    "                    orig_cat = int(INV_CAT_MAP.get(int(lab), int(lab)))\n",
    "                    rec = {\n",
    "                        'image_id': img_id,\n",
    "                        'category_id': orig_cat,\n",
    "                        'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n",
    "                        'score': float(s)\n",
    "                    }\n",
    "                    fw.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "            # Bellek temizliği (batch bazlı)\n",
    "            del images, outputs\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            processed += len(targets)\n",
    "    return processed\n",
    "\n",
    "# Tüm seçilen split'i işle (RAM şişmeden)\n",
    "processed = collect_detections_stream(score_thr=cfg.EVAL_SCORE_THR)\n",
    "print(f'Processed images ({split}):', processed)\n",
    "\n",
    "# JSONL -> JSON Array (stream ederek)\n",
    "with open(DETS_JSONL, 'r', encoding='utf-8') as fr, open(DETS_JSON, 'w', encoding='utf-8') as fw:\n",
    "    fw.write('[')\n",
    "    first = True\n",
    "    for line in fr:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if not first:\n",
    "            fw.write(',')\n",
    "        fw.write(line)\n",
    "        first = False\n",
    "    fw.write(']')\n",
    "\n",
    "# Evaluate mAP\n",
    "# COCO loadRes dosya yolunu kabul eder (JSON array formatında)\n",
    "try:\n",
    "    cocoDt = cocoGt.loadRes(DETS_JSON)\n",
    "except Exception as e:\n",
    "    print('Failed to load detections for COCOeval:', e)\n",
    "    cocoDt = None\n",
    "\n",
    "if cocoDt is None:\n",
    "    print('No detections to evaluate or load failed.')\n",
    "else:\n",
    "    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    # Save metrics\n",
    "    metrics = {\n",
    "        'AP@[.5:.95]': float(cocoEval.stats[0]),\n",
    "        'AP@0.5': float(cocoEval.stats[1]),\n",
    "        'AP@0.75': float(cocoEval.stats[2])\n",
    "    }\n",
    "    with open(os.path.join(REPORT_DIR, f'metrics_{split}.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics, f)\n",
    "    print('Saved metrics to', os.path.join(REPORT_DIR, f'metrics_{split}.json'))\n",
    "    # Bellek temizliği\n",
    "    del cocoDt, cocoEval\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Çıktı Özeti (RUN_DIR, checkpoint ve raporlar)\n",
    "import os, glob, json\n",
    "\n",
    "if 'RUN_DIR' not in globals():\n",
    "    print('RUN_DIR tanımlı değil. Önce Config hücresini çalıştırın.')\n",
    "else:\n",
    "    print('RUN_DIR          :', RUN_DIR)\n",
    "    ckpt_dir = os.path.join(RUN_DIR, 'checkpoints')\n",
    "    rep_dir  = os.path.join(RUN_DIR, 'reports')\n",
    "\n",
    "    print('\\n[checkpoints]')\n",
    "    ckpts = sorted(glob.glob(os.path.join(ckpt_dir, '*.pt')))\n",
    "    print('adet:', len(ckpts))\n",
    "    if ckpts:\n",
    "        print('son:', ckpts[-1])\n",
    "\n",
    "    print('\\n[reports]')\n",
    "    if os.path.isdir(rep_dir):\n",
    "        reps = sorted(glob.glob(os.path.join(rep_dir, '*')))\n",
    "        for p in reps[:20]:\n",
    "            print('-', os.path.basename(p))\n",
    "        # metrics_<split>.json varsa göster\n",
    "        for split_name in ['train', 'test']:\n",
    "            mpath = os.path.join(rep_dir, f'metrics_{split_name}.json')\n",
    "            if os.path.exists(mpath):\n",
    "                try:\n",
    "                    with open(mpath, 'r', encoding='utf-8') as f:\n",
    "                        metrics = json.load(f)\n",
    "                    print(f\"\\nmetrics_{split_name}.json:\", metrics)\n",
    "                except Exception as e:\n",
    "                    print(f\"metrics_{split_name}.json okunamadı:\", e)\n",
    "    else:\n",
    "        print('Rapor klasörü yok: önce değerlendirme hücresini çalıştırın.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a64596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Probe: JSON yapısı, anahtarlar ve top kategori özetleri\n",
    "import os, json, glob\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "REPORT_DIR = os.path.join(RUN_DIR, 'reports') if 'RUN_DIR' in globals() else None\n",
    "if REPORT_DIR:\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "probe = {\n",
    "    'json_root': f\"{cfg.OUT_ROOT}/jsonlar\",\n",
    "    'files_scanned': [],\n",
    "    'per_file': [],\n",
    "    'annotation_keys_union': [],\n",
    "}\n",
    "\n",
    "json_files = sorted(glob.glob(f\"{cfg.OUT_ROOT}/jsonlar/*.json\"))\n",
    "print({'json_count': len(json_files)})\n",
    "sample_files = json_files[:3]\n",
    "print('sample_files:', [os.path.basename(p) for p in sample_files])\n",
    "probe['files_scanned'] = [os.path.basename(p) for p in sample_files]\n",
    "\n",
    "ann_keys_union = set()\n",
    "\n",
    "for path in sample_files:\n",
    "    entry = {'file': os.path.basename(path)}\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print('failed to read', path, e)\n",
    "        entry['error'] = str(e)\n",
    "        probe['per_file'].append(entry)\n",
    "        continue\n",
    "\n",
    "    top_keys = list(data.keys())\n",
    "    entry['top_keys'] = top_keys\n",
    "    print(f\"\\n[{os.path.basename(path)}] top-level keys:\", top_keys)\n",
    "\n",
    "    cats = data.get('categories')\n",
    "    if cats is None:\n",
    "        print('categories: NONE')\n",
    "        entry['categories'] = {'present': False}\n",
    "    else:\n",
    "        if isinstance(cats, dict):\n",
    "            cats_list = list(cats.values())\n",
    "        else:\n",
    "            cats_list = cats\n",
    "        print('categories: present, len =', len(cats_list))\n",
    "        entry['categories'] = {'present': True, 'len': len(cats_list)}\n",
    "        for c in cats_list[:3]:\n",
    "            cid = c.get('id')\n",
    "            name = c.get('name') or c.get('category_name')\n",
    "            print('  sample category ->', {'id': cid, 'name': name})\n",
    "\n",
    "    anns = data.get('annotations') or []\n",
    "    if isinstance(anns, dict):\n",
    "        ann_iter = list(anns.values())\n",
    "    else:\n",
    "        ann_iter = anns\n",
    "    print('annotations len =', len(ann_iter))\n",
    "\n",
    "    # Anahtar kümeleri ve isim adaylarını ara\n",
    "    ann_keys = set()\n",
    "    name_hits = {}\n",
    "    counts = Counter()\n",
    "    candidate_keys = [\n",
    "        'category_name','cat_name','name','class_name','class',\n",
    "        'symbol','label','semantic','semantic_name','cat','category'\n",
    "    ]\n",
    "\n",
    "    for a in ann_iter[:1000]:\n",
    "        if isinstance(a, dict):\n",
    "            ann_keys.update(a.keys())\n",
    "            cid_val = a.get('cat_id') or a.get('category_id')\n",
    "            try:\n",
    "                cid = int(cid_val)\n",
    "            except Exception:\n",
    "                cid = None\n",
    "            if cid is not None:\n",
    "                counts[cid] += 1\n",
    "                if cid not in name_hits:\n",
    "                    for k in candidate_keys:\n",
    "                        v = a.get(k)\n",
    "                        if isinstance(v, str) and v:\n",
    "                            name_hits[cid] = v\n",
    "                            break\n",
    "    ann_keys_union.update(ann_keys)\n",
    "\n",
    "    entry['annotation_keys'] = sorted(list(ann_keys))\n",
    "    entry['name_hits_count'] = len(name_hits)\n",
    "    entry['top_categories'] = [\n",
    "        {'category_id': int(cid), 'count': int(cnt), 'name': name_hits.get(cid)}\n",
    "        for cid, cnt in counts.most_common(20)\n",
    "    ]\n",
    "    print('annotation keys (sample):', sorted(list(ann_keys))[:20])\n",
    "    print('top 10 categories by count:')\n",
    "    for x in entry['top_categories'][:10]:\n",
    "        print(' ', x)\n",
    "\n",
    "    probe['per_file'].append(entry)\n",
    "\n",
    "probe['annotation_keys_union'] = sorted(list(ann_keys_union))\n",
    "\n",
    "if REPORT_DIR:\n",
    "    out_path = os.path.join(REPORT_DIR, 'dataset_probe.json')\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(probe, f, ensure_ascii=False, indent=2)\n",
    "    print('Dataset probe saved ->', out_path)\n",
    "else:\n",
    "    print('RUN_DIR tanımlı değil; JSON raporu kaydedilemedi.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-safe overrides for Colab (OOM mitigation)\n",
    "import os, torch\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "try:\n",
    "    from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "    if 'model' in globals() and isinstance(model, MaskRCNN):\n",
    "        # Resize image limits if available on model transform\n",
    "        if hasattr(model.transform, 'min_size'):\n",
    "            # Use list to avoid len(int) error in torchvision transform\n",
    "            model.transform.min_size = [600]\n",
    "        if hasattr(model.transform, 'max_size'):\n",
    "            model.transform.max_size = 1024\n",
    "        # RPN/ROI tuning\n",
    "        if hasattr(model, 'rpn'):\n",
    "            if hasattr(model.rpn, 'pre_nms_top_n'):\n",
    "                model.rpn.pre_nms_top_n = dict(training=1000, testing=1000)\n",
    "            if hasattr(model.rpn, 'post_nms_top_n'):\n",
    "                model.rpn.post_nms_top_n = dict(training=500, testing=300)\n",
    "        if hasattr(model, 'roi_heads'):\n",
    "            if hasattr(model.roi_heads, 'detections_per_img'):\n",
    "                model.roi_heads.detections_per_img = 50\n",
    "            if hasattr(model.roi_heads, 'box_batch_size_per_image'):\n",
    "                model.roi_heads.box_batch_size_per_image = 256\n",
    "    else:\n",
    "        print('Model not yet defined; will apply when available.')\n",
    "except Exception as e:\n",
    "    print('OOM overrides skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab: categories.json'ı Drive'dan kopyala (opsiyonel ama tavsiye)\n",
    "import os, shutil\n",
    "\n",
    "IN_COLAB = 'google.colab' in globals() or 'google.colab' in str(get_ipython())\n",
    "LOCAL_REF_DIR = os.path.join(os.getcwd(), 'understanding_dataset')\n",
    "LOCAL_REF_PATH = os.path.join(LOCAL_REF_DIR, 'categories.json')\n",
    "# Kullanıcının belirttiği konum + önceki varsayılanı dene (ilk bulunanı kopyala)\n",
    "DRIVE_REF_CANDIDATES = [\n",
    "    '/content/drive/MyDrive/omr_dataset/dataset/ds2/categories.json',\n",
    "    '/content/drive/MyDrive/omr_copilot/understanding_dataset/categories.json',\n",
    "]\n",
    "\n",
    "os.makedirs(LOCAL_REF_DIR, exist_ok=True)\n",
    "\n",
    "if IN_COLAB:\n",
    "    src = None\n",
    "    for p in DRIVE_REF_CANDIDATES:\n",
    "        if os.path.exists(p):\n",
    "            src = p\n",
    "            break\n",
    "    if src:\n",
    "        shutil.copy2(src, LOCAL_REF_PATH)\n",
    "        print({'copied': True, 'from': src, 'to': LOCAL_REF_PATH})\n",
    "    else:\n",
    "        print({'copied': False, 'reason': 'Drive path not found', 'tried': DRIVE_REF_CANDIDATES})\n",
    "else:\n",
    "    print('Not in Colab; skipping Drive copy.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07232940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient accumulation training loop to reduce peak memory\n",
    "try:\n",
    "    accum_steps = 2\n",
    "    if 'train_loader' in globals() and 'model' in globals() and 'optimizer' in globals():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        from torch.amp import autocast, GradScaler\n",
    "        scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "        model.train()\n",
    "        step = 0\n",
    "        for epoch in range(1):  # set your desired number of epochs elsewhere\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            for images, targets in train_loader:\n",
    "                images = [img.to(device, non_blocking=True) for img in images]\n",
    "                targets = [{k: (v.to(device) if torch.is_tensor(v) else v) for k, v in t.items()} for t in targets]\n",
    "                with autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses = sum(loss for loss in loss_dict.values())\n",
    "                scaler.scale(losses / accum_steps).backward()\n",
    "                step += 1\n",
    "                if step % accum_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                del images, targets, loss_dict, losses\n",
    "                torch.cuda.synchronize()\n",
    "                torch.cuda.empty_cache()\n",
    "        print('Accumulation loop finished (for demo). Integrate into your main loop as needed.')\n",
    "    else:\n",
    "        print('train_loader/model/optimizer not ready; plug this into your training cell.')\n",
    "except Exception as e:\n",
    "    print('Accumulation loop skipped:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
